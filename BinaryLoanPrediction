{"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84894,"databundleVersionId":9709193,"sourceType":"competition"}],"dockerImageVersionId":30749,"isInternetEnabled":true,"language":"rmarkdown","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jimgruman/it-pays-to-discover?scriptVersionId=198981299\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"---\ntitle: \"Loan Approval\"\ndate: '`r Sys.Date()`'\noutput:\n  html_document:\n    number_sections: true\n    fig_caption: true\n    toc: true\n    fig_width: 7\n    fig_height: 4.5\n    theme: cosmo\n    highlight: tango\n    code_folding: hide\n---\n  \n# Introduction  {.tabset .tabset-fade .tabset-pills}\n\nThe goal of this competition is to build classification models to predict loan approvals.\n\nMy notebook serves as a demonstration of some of the possible techniques available to arrive at a solution.  I intend to add to this as I have time available. Your questions and comments are welcome.\n\nIf you fork this on kaggle, be sure to choose the kernel Environment setting for \"Always use latest environment\"\n\nLets dive right in.\n\nThe Kaggle kernels have many of the common r packages built in.  \n\n## Load libraries\n\nIn addition to `tidymodels` we will load the `bonsai` interface to lightgbm.\n\n```{r }\n#| label: setup\n#| warning: false\n#| message: false\n\nif (dir.exists(\"/kaggle\")){\n  path <- \"/kaggle/input/playground-series-s4e10/\"\n\noptions(repos = c(CRAN = \"https://packagemanager.posit.co/cran/2021-03-22\"))\n#install.packages(\"splines2\", quiet = TRUE)\n    \ncores <- future::availableCores()\n\n} else {\n  path <- stringr::str_c(here::here(\"data\"),\"/\")\n\ncores <- future::availableCores(omit = 1)\n}\n\n \nsuppressPackageStartupMessages({\nlibrary(tidyverse, quietly = TRUE) # metapackage of all tidyverse packages\nlibrary(tidymodels) # metapackage see https://www.tidymodels.org/\nlibrary(bonsai)\nlibrary(brulee)\n})\n\nlibrary(splines2)\n\ntidymodels_prefer()\n\noptions(tidymodels.dark = TRUE)\n\ntheme_set(cowplot::theme_minimal_grid())\n\n```\n\n\n## Load Data\n\n```{r }\n#| label: load data\n#| warning: false\n#| message: false\n\n\ntrain_spec <- cols(\n  id = col_integer(),\n  person_age = col_integer(),\n  person_indome = col_integer(),\n  person_home_ownership = readr::col_character(),\n  person_emp_length = col_double(),\n  loan_intent = col_character(),\n  loan_grade = col_character(),\n  loan_amnt = col_integer(),\n  loan_int_rate = col_double(),\n  loan_percent_income = col_double(),\n  cb_person_default_on_file = col_character(),\n  cb_person_cred_hist_length = col_integer(),\n  loan_status = col_character()\n)\n\n\ncompetition_spec <- cols(\n  id = col_integer(),\n  person_age = col_integer(),\n  person_indome = col_integer(),\n  person_home_ownership = readr::col_character(),\n  person_emp_length = col_double(),\n  loan_intent = col_character(),\n  loan_grade = col_character(),\n  loan_amnt = col_integer(),\n  loan_int_rate = col_double(),\n  loan_percent_income = col_double(),\n  cb_person_default_on_file = col_character(),\n  cb_person_cred_hist_length = col_integer(),\n)\n\n\npreprocessor <- function(dataframe) {\n\ndataframe <- dataframe %>%\n    janitor::clean_names() %>%\n    \n    mutate(across(c(where(is.numeric), -id), ~ as.factor(.x), .names = \"factor_{.col}\")) |>\n    mutate(loan_gap =log1p(person_income / loan_amnt - loan_percent_income)) |> \n    \n    mutate(across(c(where(is.character)), ~ as.factor(.x))) \n\n\nreturn(dataframe)\n}\n\nraw_df <- read_csv(str_c(path, \"train.csv\"),\n                   col_types = train_spec,\n                   show_col_types = FALSE) %>%\n          preprocessor() \n\ntst_df <- read_csv(str_c(path, \"test.csv\"),\n                   col_types = competition_spec,\n                   show_col_types = FALSE)  %>% \n  preprocessor() \n\nall_df <-\n    bind_rows(raw_df %>% mutate(source = \"train\"),\n              tst_df %>% mutate(source = \"test\"))\n\ntrain_df <- all_df %>% \n  filter(source == \"train\") %>% \n  select(-source) \n\ncompetition_df <- all_df %>% \n  filter(source == \"test\") %>% \n  select(-source, -loan_status)\n\nfeatures <- train_df %>%\n  select(-id, -loan_status) %>%\n  names()\n\ntrain_df <- train_df %>% \n  distinct(pick(all_of(features)), .keep_all = TRUE)\n\nnom_features <- train_df %>%\n  select(all_of(features)) %>%\n  select(where(is.character), where(is.factor)) %>%\n  names() \n\nlogical_features <- train_df %>%\n  select(all_of(features)) %>%\n  select(where(is.logical)) %>%\n  names() \n\nnum_features <- train_df %>%\n  select(all_of(features)) %>%\n  select(where(is.numeric)) %>%\n  names()\n\n\n```\n\nNominal features:\n\n`r nom_features`\n\nNumeric features: \n\n`r num_features`\n\nLogical features: \n\n`r logical_features`\n\n\nSize of the combined train and competition datasets:\n\n`r nrow(all_df)`\n\nSize of the split made available to machine learning\n\n`r nrow(train_df)`\n\n\n# EDA {.tabset .tabset-fade .tabset-pills}\n\n## Numeric features\n\nConsider where features require univariate transformation, or clipping outliers.\n```{r}\n#| label: numeric\n#| warning: false\n#| message: false\n#| fig.height: 12\n#| fig.width: 6\n\ntrain_df %>% \n  select(all_of(num_features), loan_status ) %>% \n  pivot_longer(-loan_status,\n    names_to = \"metric\",\n    values_to = \"value\"\n  ) %>%\n  ggplot(aes(value, fill = loan_status)) +\n  geom_histogram(show.legend = FALSE, bins = 200) +\n   facet_wrap(vars(metric), scales = \"free\", ncol = 1) +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        plot.title.position = \"plot\") +\n  labs(color = NULL, fill = \"Loan Status\",\n       title = \"Numeric Feature Univariate Distributions\",\n       caption = \"Data: Kaggle.com | Visual: Jim Gruman\")\n\n```\n\n\n## Nominal features\n\nExplore the distribution of outcome class by factor level, and the factor levels that exist in test that do not exist in training.\n\n\n```{r}\n#| label: nominal\n#| warning: false\n#| message: false\n#| fig.height: 12\n#| fig.width: 12\n\n\nif(length(nom_features) >0){\n\ntrain_df %>% \n  select(all_of(nom_features), loan_status) %>% \n  mutate(across(nom_features, fct_lump_n,n = 10, other_level = 'other')) %>%\n  pivot_longer(-loan_status,\n    names_to = \"metric\",\n    values_to = \"value\"\n  ) %>%\n    \n  summarise(n = n(),\n            .by = c(loan_status, metric, value)) %>%\n      \n  mutate(value = tidytext::reorder_within(value, n, metric)) %>%\n    \n  ggplot(aes(x = n, y = value, fill = loan_status)) +\n  geom_col(aes(x = n)) +\n  \n  tidytext::scale_y_reordered() +\n  scale_x_continuous(n.breaks = 3, guide = guide_axis(n.dodge = 2))  +\n  facet_wrap(vars(metric), scales = \"free\", ncol = 2) +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n       legend.position = \"bottom\") +\n  labs(title = \"Nominal Feature Counts\",\n       fill = NULL,\n       caption = \"Data: Kaggle | Visual: Jim Gruman\")\n\n}\n\n```\n\n## Logical features\n\n```{r}\n#| label: logical\n#| warning: false\n#| message: false\n#| fig.height: 6\n#| fig.width: 6\n\n\nif(length(logical_features) >0){\n\ntrain_df %>% \n  select(all_of(logical_features), class) %>% \n  pivot_longer(-class,\n    names_to = \"metric\",\n    values_to = \"value\"\n  ) %>%\n  ggplot(aes(y = value, fill = class)) +\n  geom_bar() +\n  scale_x_continuous(n.breaks = 3, guide = guide_axis(n.dodge = 2)) +\n   facet_wrap(vars(metric), scales = \"free\", ncol = 2) +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n       legend.position = \"bottom\") +\n  labs(title = \"Logical Feature Counts\",\n       fill = \"Class\",\n       caption = \"Data: Kaggle.com | Visual: Jim Gruman\")\n}\n\n```\n\n## Counts of Missingness\n                  \n```{r}\n#| label: counts of missingness\n\ntrain_df %>% \n  summarize(across(all_of(features), function(x) sum(is.na(x)))) %>% \n  pivot_longer(everything(),\n              names_to = \"feature\",\n              values_to = \"Count of Missing\") %>% \n                   knitr::kable()\n                   \n\n                  \n```\n\n## Counts of Distinct\n                   \nThis dataset has quite a few unusual factor levels. And more important, there are factor levels in test that do not appear in train.\n               \n```{r}\n#| label: counts of distinct\n               \ntrain_df %>%\n  summarize(across(all_of(features), n_distinct)) %>%\n  pivot_longer(everything(), names_to = \"feature\", values_to = \"Count of distinct train\") |>\n  left_join(\n    tst_df %>%\n      summarize(across(all_of(features), n_distinct)) %>%\n      pivot_longer(everything(), names_to = \"feature\", values_to = \"Count of distinct test\")\n  ) %>% \n                   knitr::kable()\n               \n```\n\n## Duplicated\n\nIs this competition transaction already in the training data with a correct label?\n\n```{r}\n#| label: duplicates\n#| warning: false\n#| message: false\nall_df %>%\n    group_by_at(features) %>%\n    mutate(num_dups = n(),\n           dup_id = row_number()) %>% \n    ungroup() %>%\n    group_by(source) %>%\n    mutate(is_duplicated = dup_id > 1) %>% \n    count(is_duplicated) %>% \n                   knitr::kable()\n               \n\n```\n                   \n\n\n\n## Target\n\n```{r}\n#| label: outcome \n#| warning: false\n#| message: false\n#| fig.width: 6\n\n\ntrain_df %>% \n  summarize(outcome_sum = n(),\n            .by = loan_status) %>%\n  arrange(outcome_sum) %>%\n  mutate(prop = outcome_sum / nrow(train_df)) %>%\n  mutate(ypos = cumsum(prop) - 0.5 * prop) %>%\n  ggplot(aes(x = \"\", y = prop, fill = loan_status)) +\n  geom_bar(stat = \"identity\", width = 1, show.legend = FALSE) +\n  geom_text(aes(y = ypos, label = paste0(loan_status\n                                  ,\"\\n\",round(prop,2)*100,\"%\")),\n            color = \"white\",\n            nudge_x = 0,\n            size = 3) +\n  coord_polar(\"y\", start = 0) +\n  theme_void() + \n  labs(title = \"Loan Status\",\n       caption = \"Data: Kaggle.com | Visual: Jim Gruman\")\n\n```\n                              \n           \n                \n# Machine Learning {.tabset .tabset-fade .tabset-pills}\n\n\n## Recipe\n\n```{r}\n#| label: recipe\n                   \nrec <- recipe(\n    \n    formula(paste0(\"loan_status ~ \", \n               str_c(features,  collapse = \" + \"))),\n    data = train_df\n  ) %>% \n  step_novel(all_nominal_predictors()) \n                   \nfolds <- vfold_cv(train_df, \n                  v = 3,\n                  repeats = 1,\n                  strata = loan_status)    \n                   \nctrl <- finetune::control_sim_anneal(     \n     verbose = FALSE,\n     verbose_iter = TRUE,\n     parallel_over = \"everything\",\n     event_level = \"second\",\n     save_pred = FALSE,\n     save_workflow = FALSE)                   \n                                     \n```\n\n\n\n## Lightgbm\n\n```{r}\n#| label: lgbm\n#| warning: false\n#| message: false\n#| fig.width: 12\n\nboost_tree_lgbm_spec <- \n  boost_tree(\n    trees = 700L,\n   tree_depth = tune(),\n   learn_rate =  tune(),\n   min_n = tune(),\n#   mtry = tune(),\n   loss_reduction = 0\n  ) %>% \n  set_engine(engine = \"lightgbm\",\n             is_unbalance = TRUE,\n             num_leaves = tune(),\n             num_threads = cores\n             ) %>%\n  set_mode(mode = \"classification\") \n                   \nwf <- workflow(rec,\n               boost_tree_lgbm_spec) \n\nparam <- wf %>%\n   extract_parameter_set_dials() %>%\n   recipes::update(\n      min_n = min_n(range = c(70,130)),\n      tree_depth = tree_depth(range = c(4,30)),\n      learn_rate = learn_rate(range = c(-1.5,-2.5)),\n      num_leaves = num_leaves(range = c(500,900))\n   ) %>%\n   dials::finalize(raw_df)                 \n\nburnin <- tune_grid(\n  wf,\n  grid = 5,\n  resamples = folds,\n  control = ctrl,\n  metrics = metric_set(roc_auc, accuracy),\n  param_info = param)\n\nlgbm_rs <- finetune::tune_sim_anneal(\n  wf,\n  resamples = folds,\n  iter = 11,\n  initial = burnin,\n  control = ctrl,\n  metrics =  metric_set(roc_auc, accuracy),\n  param_info = param) \n\nshow_best(lgbm_rs, metric = \"roc_auc\")  \n\nautoplot(lgbm_rs)\n\ncollect_metrics(lgbm_rs) %>% \n  filter(.metric == \"roc_auc\") %>% \n  mutate(.config = fct_reorder(.config, mean)) %>% \n  ggplot(aes(mean, .config)) +\n  geom_point() +\n  geom_errorbarh(aes(xmin = mean - std_err, xmax = mean + std_err)) +\n  labs(title = \"ROC across resample folds with std_err\")\n                   \n\n```\n                   \n                   \n## Brulee                   \n\n```{r}\n#| label: brulee\n#| warning: false\n#| message: false\n#| fig.width: 12\n\n\nmlp_brulee_spec <-\n  mlp(hidden_units = 5L, \n      epochs = 800, \n      dropout = tune(), \n      learn_rate = 0.0005, \n      ) %>%\n  set_engine('brulee',\n             rate_schedule = \"cyclic\",\n             validation = 0.03,\n             stop_iter = 20L) %>%\n  set_mode('classification')\n\nbrulee_rec <- rec %>%\n  \n  step_dummy(person_home_ownership, loan_intent, loan_grade, cb_person_default_on_file ) %>% \n  \n  embed::step_embed(factor_person_age , \n                    num_terms = 3,\n                    hidden_units = 3,\n                    options = embed::embed_control(\n                      loss = \"mse\",\n                      optimizer = \"adam\",\n                      epochs = 20,\n                      validation_split = 0,\n                      batch_size = 32,\n                      verbose = 0\n                    ),\n                    outcome = vars(loan_status)) |> \n  \n  embed::step_embed(factor_person_income              , \n                    num_terms = 3,\n                    hidden_units = 3,\n                    options = embed::embed_control(\n                      loss = \"mse\",\n                      optimizer = \"adam\",\n                      epochs = 20,\n                      validation_split = 0,\n                      batch_size = 32,\n                      verbose = 0\n                    ),\n                    outcome = vars(loan_status)) |> \n  \n  embed::step_embed(factor_person_emp_length          , \n                    num_terms = 3,\n                    hidden_units = 3,\n                    options = embed::embed_control(\n                      loss = \"mse\",\n                      optimizer = \"adam\",\n                      epochs = 20,\n                      validation_split = 0,\n                      batch_size = 32,\n                      verbose = 0\n                    ),\n                    outcome = vars(loan_status)) |> \n  \n  embed::step_embed(factor_loan_amnt                  ,\n                    num_terms = 3,\n                    hidden_units = 3,\n                    options = embed::embed_control(\n                      loss = \"mse\",\n                      optimizer = \"adam\",\n                      epochs = 20,\n                      validation_split = 0,\n                      batch_size = 32,\n                      verbose = 0\n                    ),\n                    outcome = vars(loan_status)) |>\n    \n   embed::step_embed(factor_loan_int_rate                  ,\n                    num_terms = 3,\n                    hidden_units = 3,\n                    options = embed::embed_control(\n                      loss = \"mse\",\n                      optimizer = \"adam\",\n                      epochs = 20,\n                      validation_split = 0,\n                      batch_size = 32,\n                      verbose = 0\n                    ),\n                    outcome = vars(loan_status)) |>\n      embed::step_embed(factor_loan_percent_income                   ,\n                    num_terms = 3,\n                    hidden_units = 3,\n                    options = embed::embed_control(\n                      loss = \"mse\",\n                      optimizer = \"adam\",\n                      epochs = 20,\n                      validation_split = 0,\n                      batch_size = 32,\n                      verbose = 0\n                    ),\n                    outcome = vars(loan_status)) |>\n    \n          embed::step_embed(factor_cb_person_cred_hist_length                   ,\n                    num_terms = 3,\n                    hidden_units = 3,\n                    options = embed::embed_control(\n                      loss = \"mse\",\n                      optimizer = \"adam\",\n                      epochs = 20,\n                      validation_split = 0,\n                      batch_size = 32,\n                      verbose = 0\n                    ),\n                    outcome = vars(loan_status)) |>\n  \n  step_zv(all_predictors()) |>\n  step_normalize(all_predictors())\n                   \nwf <- workflow(brulee_rec,\n               mlp_brulee_spec) \n\n param <- wf %>%\n   extract_parameter_set_dials() %>%\n   recipes::update(\n      dropout = dropout(range = c(0,0.08))) %>%\n   dials::finalize(train_df)                    \n                   \nbrulee_rs <- tune_grid(wf,\n                       grid = 3,\n  resamples = folds,\n  control = ctrl,\n  metrics = metric_set(roc_auc, accuracy),\n  param_info = param)                   \n                   \nautoplot(brulee_rs)\n\n\ncollect_metrics(brulee_rs) %>% \n  filter(.metric == \"roc_auc\") %>% \n  mutate(.config = fct_reorder(.config, -mean)) %>% \n  ggplot(aes(mean, .config)) +\n  geom_point() +\n  geom_errorbarh(aes(xmin = mean - std_err, xmax = mean + std_err)) +\n  labs(title = \"RMSE across resample folds with std_err\")     \n```                   \n \n ## Stacks Ensemble\n                   \n```{r}\n#| label: stacks\n#| warning: false\n#| message: false                  \n                   \nloan_st <- \n  stacks() %>%\n  add_candidates(brulee_rs) %>%\n  add_candidates(lgbm_rs) %>%\n  blend_predictions(      \n      metric = metric_set(rmse),\n      penalty = c(10^seq(-1.3, -0.1, 0.1)),\n      non_negative = TRUE,\n      control = tune::control_grid(allow_par = TRUE))\n                   \nautoplot(loan_st)                      \nautoplot(loan_st, type = \"weights\") \nloan_model <-\n  loan_st %>%\n  fit_members()                       \n```                   \n                   \n# Submission\n                   \n```{r}\n#| label: submission\n#| warning: false\n#| message: false\n\naugment(loan_model, train_df, type = \"prob\") %>%\n    yardstick::roc_curve(loan_status, .pred_0) %>% \n    autoplot()  +\n    labs(title = \"ROC Curve\")\n                   \nsubmit_df <-  augment(loan_model, competition_df) %>%\n       select(id, class = .pred_1)\n\nhead(submit_df)  %>% \n     knitr::kable()      \n\nsubmit_df  %>% \n  write_csv(\"submission.csv\")\n```   ","metadata":{"_uuid":"77a334ee-923c-481a-acb3-7f528936b873","_cell_guid":"8e04b251-ac8f-4a2c-bffb-30f31d125cc9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}