{"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"}],"dockerImageVersionId":30749,"isInternetEnabled":true,"language":"rmarkdown","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jimgruman/bank-deposit-class?scriptVersionId=253675710\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"---\ntitle: \"Bank Deposit Binary Classifcation\"\ndate: '`r Sys.Date()`'\noutput:\n  html_document:\n    number_sections: true\n    fig_caption: true\n    toc: true\n    fig_width: 7\n    fig_height: 4.5\n    theme: cosmo\n    highlight: tango\n    code_folding: hide\n---\n  \n# Introduction  {.tabset .tabset-fade .tabset-pills}\n\nThe goal of this competition is to predict a subscription to a bank term deposit.\n\nMy notebook serves as a demonstration of some of the possible techniques available to arrive at a solution.  I intend to add to this as I have time available. Your questions and comments are welcome.\n\nLets dive right in.\n\nThe Kaggle kernels have many of the common r packages built in.  \n\n![https://unsplash.com/@amseaman](https://images.unsplash.com/photo-1521220546621-cf34a1165c67?q=80&w=1176&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D)\n\n## Load libraries\n\n```{r }\n#| label: setup\n#| warning: false\n#| message: false\n\nif (dir.exists(\"/kaggle\")){\n  path <- \"/kaggle/input/playground-series-s5e8/\"\n # orig_path <- \"/kaggle/input/extrovert-vs-introvert-behavior-data-backup/\"\n\n#options(repos = c(CRAN = \"https://packagemanager.posit.co/cran/2025-06-30\"))\ninstall.packages(\"pak\")\npak::pak(\"bonsai\")\n\nremotes::install_url('https://github.com/catboost/catboost/releases/download/v1.2.8/catboost-R-linux-x86_64-1.2.8.tgz', \n                     INSTALL_opts = c(\"--no-multiarch\", \"--no-test-load\"),\n                    quiet = TRUE)  \n\n# future::plan(\"multisession\", workers = future::availableCores())    \n\n} else {\n  path <- stringr::str_c(here::here(\"data\"),\"/\")\n  orig_path <- stringr::str_c(here::here(\"data\"),\"/\")\n\n  future::plan(\"multisession\", workers = future::availableCores(omit = 2))\n  \n}\n \nsuppressPackageStartupMessages({\nlibrary(tidyverse, quietly = TRUE) # metapackage of all tidyverse packages\nlibrary(tidymodels) # metapackage see https://www.tidymodels.org/\n\nlibrary(correlationfunnel)    \n  \nlibrary(bonsai)  # interface to lighgbm and catboost\nlibrary(catboost)\n\nlibrary(stacks)  # ensembling\n    \nlibrary(DALEXtra) # Tidymodels Explainability     \n    \nlibrary(probably) # model calibration\n})\n\ntidymodels_prefer()\nconflicted::conflicts_prefer(brulee::coef)\n\noptions(tidymodels.dark = TRUE)\n\ntheme_set(ggdark::dark_theme_minimal())\n\n```\n\n## Load Data\n\n\n```{r }\n#| label: load data\n#| warning: false\n#| message: false\n\npreprocessor <- function(dataframe) {\n\ndataframe <- dataframe %>%\n    janitor::clean_names() %>%\n\n#    mutate(sum_na =  rowSums(is.na(.))) |>\n\n    mutate(across(c(where(is.character)), \\(x) as.factor(x)))  \n #   mutate(across(c(stage_fear, drained_after_socializing), \\(x) as.numeric(x) - 1)) |>\n\n #    mutate(\n #     time_spent_alone_f = factor(str_c(\"tsa\", time_spent_alone)),\n #     social_event_attendance_f  = factor(str_c(\"sea\", social_event_attendance )),\n #     going_outside_f  = factor(str_c(\"go\", going_outside )),\n #     friends_circle_size_f  = factor(str_c(\"fcs\", friends_circle_size )),\n #     post_frequency_f  = factor(str_c(\"pf\", post_frequency))\n #   ) \n\nreturn(dataframe)\n}\n\nraw_df <- read_csv(str_c(path, \"train.csv\"),\n                   show_col_types = FALSE) |> \n\n#          bind_rows(\n#                     read_csv(str_c(orig_path,\"personality_dataset.csv\")) |>\n#                          mutate(Personality = if_else(Personality == \"Extrovert\", \"Introvert\", \"Extrovert\"))  # flip per @paddykb\n#          ) |>\n\n          preprocessor() |>\n          mutate(y = factor(y))\n\ntst_df <- read_csv(str_c(path, \"test.csv\"),\n                   show_col_types = FALSE)  |>  \n  preprocessor() \n\n# because we already know the test set, let's remove the train set factor levels that do not correspond with anything on the test set\nfor (col in names(raw_df)) {\n    if (is.factor(raw_df[[col]]) & col != \"y\") {\n      # Get levels in train and test dataframes\n      raw_levels <- levels(raw_df[[col]])\n      tst_levels <- levels(tst_df[[col]])\n      \n      # Identify levels in train not in test\n      new_levels <- setdiff(raw_levels, tst_levels)\n      \n      # Set these levels to NA in train dataframe\n      raw_df[[col]] <- factor(raw_df[[col]], levels = c(tst_levels, new_levels))\n      raw_df[[col]][raw_df[[col]] %in% new_levels] <- NA_character_\n    }\n  }\n\n# the synthetic playground competitions seem to perform better when numerics are also included as factors\nall_df <-\n    bind_rows(raw_df %>% mutate(source = \"train\"),\n              tst_df %>% mutate(source = \"test\")) \n\n#cluster_fit <- all_df |> \n#  select(where(is.numeric), -id) |> \n#  mutate(across(everything(), \\(x) replace_na(x, -1))) |> \n#  mutate(across(where(is.numeric), scale)) |> \n#  kmeans(centers = 25)\n\n#all_df <- all_df |> \n#  bind_cols(tibble(cluster = factor(fitted(cluster_fit, method = \"classes\"))))\n\ntrain_df <- all_df %>% \n  filter(source == \"train\") %>% \n  select(-source) \n\ncompetition_df <- all_df %>% \n  filter(source == \"test\") %>% \n  select(-source, -y)\n\n\n```\n\n\n# EDA {.tabset .tabset-fade .tabset-pills}\n\n## Features\n\n```{r}\n#| label: Features\n#| warning: false\n#| message: false\n#| fig.width: 6\n\n\nfeatures <- train_df %>%\n  select(-id, -y) |> \n  names()\n\ntrain_df <- train_df %>% \n  distinct(pick(all_of(features)), .keep_all = TRUE)\n\nnom_features <- train_df %>%\n  select(all_of(features)) %>%\n  select(where(is.character), where(is.factor)) %>%\n  names() \n\nlogical_features <- train_df %>%\n  select(all_of(features)) %>%\n  select(where(is.logical)) %>%\n  names() \n\nnum_features <- train_df %>%\n  select(all_of(features)) %>%\n  select(where(is.numeric)) %>%\n  names()\n```\n\nNominal features:\n\n`r nom_features`\n\nNumeric features: \n\n`r num_features`\n\nLogical features: \n\n`r logical_features`\n\n\nSize of the combined train and competition datasets:\n\n`r nrow(all_df)`\n\nSize of the split made available to machine learning\n\n`r nrow(train_df)`\n\n\n\n## Numeric features\n\n```{r}\n#| label: numeric\n#| warning: false\n#| message: false\n#| fig.height: 6\n#| fig.width: 10\n\ntrain_df %>% \n  select(all_of(num_features), y) %>% \n  pivot_longer(-y,\n    names_to = \"metric\",\n    values_to = \"value\"\n  ) %>%\n  ggplot(aes(value)) +\n  stat_density(aes(color = y), geom = \"line\", position = \"identity\") +\n  scale_color_brewer(type = \"qual\", palette = \"Dark2\") +\n  facet_wrap(vars(metric), scales = \"free\", ncol = 3) +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        plot.title.position = \"plot\") +\n  labs(color = \"y\", \n       title = \"Numeric Feature Univariate Distributions\",\n       caption = \"Data: Kaggle.com | Visual: Jim Gruman\")\n\n\n```\n\n## Nominal features\n\nExplore the distribution of outcome class by factor level.\n\n\n```{r}\n#| label: nominal\n#| warning: false\n#| message: false\n#| fig.height: 24\n#| fig.width: 12\n\n\n\ntrain_df %>% \n  select(all_of(nom_features), y) %>% \n  mutate(across(nom_features, fct_lump_n,n = 10, other_level = 'other')) %>%\n\n  pivot_longer(-y,\n    names_to = \"metric\",\n    values_to = \"value\"\n  ) %>%\n    \n  summarise(n = n(),\n            .by = c(y, metric, value)) %>%\n\n  mutate(value = tidytext::reorder_within(value, n, metric)) %>%\n    \n  ggplot(aes(x = n, y = value, fill = y)) +\n  geom_col(position = \"fill\") +\n\n  tidytext::scale_y_reordered() +\n  scale_x_continuous(n.breaks = 3, guide = guide_axis(n.dodge = 2))  +\n  scale_fill_brewer(type = \"qual\", palette = \"Dark2\") +\n  facet_wrap(vars(metric), scales = \"free\", ncol = 2) +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n       legend.position = \"bottom\") +\n  labs(title = \"Proportion of Outcome in Nominal Feature Counts\",\n       fill = NULL,\n       caption = \"Data: Kaggle | Visual: Jim Gruman\")\n\n```\n\n\n## Counts of Missingness\n\nThe original numeric features all have some missing values. \nFor the new factor features, we labeled missing as None.\n\n```{r}\n#| label: counts of missingness\n\ntrain_df %>% \n  summarize(across(all_of(features), function(x) sum(is.na(x)))) %>% \n  pivot_longer(everything(),\n              names_to = \"feature\",\n              values_to = \"Count of Missing\") %>% \n                   knitr::kable()\n\ncompetition_df %>% \n  summarize(across(all_of(features), function(x) sum(is.na(x)))) %>% \n  pivot_longer(everything(),\n              names_to = \"feature\",\n              values_to = \"Count of Missing\") %>% \n                   knitr::kable()\n\n```\n\n## Counts of Distinct\n                   \n               \n```{r}\n#| label: counts of distinct\n               \ntrain_df %>%\n  summarize(across(all_of(features), n_distinct)) %>%\n  pivot_longer(everything(), names_to = \"feature\", values_to = \"Count of distinct train\") |>\n  left_join(\n    competition_df %>%\n      summarize(across(all_of(features), n_distinct)) %>%\n      pivot_longer(everything(), names_to = \"feature\", values_to = \"Count of distinct test\"),\n    by = join_by(feature)\n  ) %>% \n                   knitr::kable()\n               \n```\n\n## Duplicated\n\nIs this competition transaction already in the training data with a correct personality?\n\n```{r}\n#| label: duplicates\n#| warning: false\n#| message: false\n\nbind_rows(train_df %>% mutate(source = \"train\"),\n              competition_df %>% mutate(y= NA_character_, source = \"test\")) |> \n    group_by_at(features) %>%\n    mutate(num_dups = n(),\n           dup_id = row_number()) %>% \n    ungroup() %>%\n    group_by(source) %>%\n    mutate(is_duplicated = dup_id > 1) %>% \n    count(is_duplicated) %>% \n                   knitr::kable()\n               \n\n```\n\n## Pairwise Correlations\n                   \n`ggcorrplot` provides a quick look at numeric features where the correlation may be significant. \n\n```{r}\n#| label: pairwise correlations\n#| fig.width: 6\n#| fig.height: 6                   \n                   \ntrain_df %>% \n  select(all_of(num_features), y) %>%\n  mutate(across(everything(), \\(x) replace_na(x, -1))) |> \n  mutate(y = as.numeric(y) -1) |> \n  cor() %>% \n  ggcorrplot::ggcorrplot(hc.order = TRUE, lab = TRUE,\n    type = \"lower\", insig = \"blank\") +\n  labs(title = \"Pairwise Correlations Training Set\")\n                   \ncompetition_df %>% \n  select(all_of(num_features)) %>% \n  mutate(across(everything(), \\(x) replace_na(x, -1))) |> \n  cor() %>% \n  ggcorrplot::ggcorrplot(hc.order = TRUE, lab = TRUE,\n    type = \"lower\", insig = \"blank\") +\n  labs(title = \"Pairwise Correlations Competition Set\")\n\n``` \n\n## Correlation Funnel\n\n\n```{r}\n#| label: correlation funnel \n#| warning: false\n#| message: false\n#| fig.width: 6\n#| fig.height: 6\n\ny_df <- train_df |>\n  select(all_of(num_features), y) %>%\n  na.omit() \n\ntrain_df %>%\n  select(all_of(num_features)) %>%\n  na.omit() |>\n  correlationfunnel::binarize(one_hot = TRUE, n_bins = 9) %>%\n  bind_cols(y_df) |>\n  mutate(y = as.numeric(y) - 1) |> \n  correlate(target = y) %>%\n  plot_correlation_funnel()\n\n```                   \n               \n\n## Target\n\n```{r}\n#| label: outcome \n#| warning: false\n#| message: false\n#| fig.width: 6\n\n\ntrain_df %>%\n  summarize(outcome_sum = n(), .by = y) %>%\n  arrange(outcome_sum) %>%\n  mutate(prop = outcome_sum / nrow(train_df)) %>%\n  mutate(ypos = cumsum(prop) - 0.5 * prop) %>%\n  ggplot(aes(x = \"\", y = prop, fill = y)) +\n  geom_bar(stat = \"identity\",\n           width = 1,\n           show.legend = FALSE) +\n  geom_text(\n    aes(\n      y = ypos,\n      label= paste0(y\n                     , \"\\n\", round(prop, 2) * 100, \"%\")\n    ),\n    color = \"white\",\n    nudge_x = 0,\n    size = 3\n  ) +\n  scale_fill_brewer(type = \"qual\", palette = \"Dark2\") +                   \n  coord_polar(\"y\", start = 0) +\n  theme(\n    axis.text = element_blank(),\n    axis.title = element_blank()  ) +\n  labs(title = \"y\", caption = \"Data: Kaggle.com | Visual: Jim Gruman\")\n\n```                            \n           \n                \n# Machine Learning {.tabset .tabset-fade .tabset-pills}\n\n## Recipe\n\n```{r}\n#| label: recipe\n                   \nbase_rec <- recipe(\n    \n    formula(paste0(\"y ~ \", \n               str_c(features,  collapse = \" + \"))),\n    data = train_df\n  ) \n                   \ndummy_rec <- base_rec|> \n  step_novel(all_nominal_predictors()) |>\n  step_unknown(all_nominal_predictors()) |>                 \n  step_impute_median(all_numeric_predictors()) |>           \n  step_interact(~ all_numeric_predictors():all_numeric_predictors()) |>\n  step_dummy(all_nominal_predictors()) |>   \n  step_zv(all_predictors()) |> \n  step_normalize(all_predictors())                    \n                 \n\nfolds <- vfold_cv(train_df, v = 3, strata = y)\n\n                                     \n```\n\n\n\n## Workflowset Ensemble\n\n```{r}\n#| label: workflowset\n#| warning: false\n#| message: false\n#| fig.width: 14\n\nboost_tree_lgbm_spec <- \n  boost_tree(\n    trees = 300L,\n   tree_depth = tune(),\n   learn_rate =  tune(),\n   min_n = tune()\n  ) %>% \n  set_engine(engine = \"lightgbm\",\n             is_unbalance = TRUE,\n             num_leaves = tune(),\n             num_threads = future::availableCores()\n             ) %>%\n  set_mode(mode = \"classification\") \n\nboost_tree_catboost_spec <- \n  boost_tree(\n    trees = 300L,\n     learn_rate =  tune()\n  ) %>% \n  set_engine(engine = \"catboost\" ) %>%\n  set_mode(mode = \"classification\") \n\nlogistic_reg_glmnet_spec <-\n  logistic_reg(penalty = tune(), mixture = tune()) %>%\n  set_engine('glmnet') \n\nnearest_neighbor_kknn_spec <-\n  nearest_neighbor(neighbors = tune(), weight_func = tune(), dist_power = tune()) |>\n  set_engine('kknn') |>\n  set_mode('classification')\n                   \n\ndep_models <- \n   workflow_set(\n      preproc = list(base = base_rec,\n                     base = base_rec,\n                     dummy = dummy_rec,\n                     dummy = dummy_rec),\n      models = list(lgbm = boost_tree_lgbm_spec,\n                    catboost = boost_tree_catboost_spec,\n                    glmnet = logistic_reg_glmnet_spec,\n                    knn = nearest_neighbor_kknn_spec),\n      cross = FALSE\n   ) %>% \n  option_add_parameters() |> \n  option_add(\n    control = finetune::control_sim_anneal(save_pred = TRUE,save_workflow = TRUE),\n    metrics = metric_set(accuracy)\n  )\n\nlgbm_params <- dep_models |> \n  extract_workflow(\"base_lgbm\") |> \n  parameters() |> \n  update(\n      min_n = min_n(range = c(30,70)),\n      tree_depth = tree_depth(range = c(20,100)),\n      learn_rate = learn_rate(range = c(-3.5,-2.7)),\n      num_leaves = num_leaves(range = c(100,150))       \n         )\n             \ncatboost_params <- dep_models |> \n  extract_workflow(\"base_catboost\") |> \n  parameters() |>\n  update(\n          learn_rate = learn_rate(range = c(-2.9,-1.9))\n  ) \n\nknn_params <- dep_models |> \n  extract_workflow(\"dummy_knn\") |> \n  parameters() |>\n  update(\n          neighbors = neighbors(range = c(55,100)),\n          weight_func = weight_func(values = c(\"rectangular\", \"gaussian\")),\n          dist_power = dist_power(range = c(1.5, 2.5))\n  ) \n\nglmnet_params <- dep_models |> \n  extract_workflow(\"dummy_glmnet\") |> \n  parameters() |>\n  update(\n          penalty = penalty(range = c(-3.5,-2.7)),\n          mixture = mixture(range = c(0.7, 0.3))\n  )                    \n                   \n                   \ndep_models <- dep_models |> \n  option_add(\n    param_info = lgbm_params,\n    id = \"base_lgbm\"\n  ) |> \n  option_add(\n    param_info = catboost_params,\n    id = \"base_catboost\"\n  ) |> \n  option_add(\n    param_info = knn_params,\n    id = \"dummy_knn\"\n  ) |>   \n  option_add(\n    param_info = glmnet_params,\n    id = \"dummy_glmnet\"\n  ) |>    \n   workflow_map(\"tune_sim_anneal\", resamples = folds, iter = 11, \n                metrics = metric_set(roc_auc, accuracy), verbose = TRUE)\n\nrank_results(dep_models, rank_metric = \"roc_auc\", select_best = TRUE)                    \n\nautoplot(dep_models) +\n  geom_text(aes(y = mean, label= wflow_id), angle = 90, vjust = 0, nudge_x = 0.4)+\n  theme(legend.position = \"none\")\n\n```\n\n## Hyperparameters \n\n```{r }                   \n#| label: parameters\n#| warning: false\n#| message: false    \n#| fig.height: 6               \n\ndep_models %>%\n  dplyr::filter(grepl(\"base_lgbm\", wflow_id)) %>%\n  dplyr::mutate(metrics = purrr::map(result, tune::collect_metrics)) %>%\n  dplyr::select(wflow_id, metrics) %>%\n  tidyr::unnest(cols = metrics) |> \n  arrange(desc(mean))\n\ndep_models |> \n  workflowsets::extract_workflow_set_result(\"base_lgbm\") |> \n  autoplot() +\n  labs(title = \"LGBM Hyperparameter Search\")\n\n                  \ndep_models %>%\n  dplyr::filter(grepl(\"base_catboost\", wflow_id)) %>%\n  dplyr::mutate(metrics = purrr::map(result, tune::collect_metrics)) %>%\n  dplyr::select(wflow_id, metrics) %>%\n  tidyr::unnest(cols = metrics) |> \n  arrange(desc(mean))\n\ndep_models |> \n  workflowsets::extract_workflow_set_result(\"base_catboost\") |> \n  autoplot() +\n  labs(title = \"Catboost Hyperparameter Search\")\n\ndep_models %>%\n  dplyr::filter(grepl(\"dummy_glmnet\", wflow_id)) %>%\n  dplyr::mutate(metrics = purrr::map(result, tune::collect_metrics)) %>%\n  dplyr::select(wflow_id, metrics) %>%\n  tidyr::unnest(cols = metrics) |> \n  arrange(desc(mean))\n\ndep_models |> \n  workflowsets::extract_workflow_set_result(\"dummy_glmnet\") |> \n  autoplot() +\n  labs(title = \"GLMNet Hyperparameter Search\")\n\ndep_models %>%\n  dplyr::filter(grepl(\"dummy_knn\", wflow_id)) %>%\n  dplyr::mutate(metrics = purrr::map(result, tune::collect_metrics)) %>%\n  dplyr::select(wflow_id, metrics) %>%\n  tidyr::unnest(cols = metrics) |> \n  arrange(desc(mean))\n\ndep_models |> \n  workflowsets::extract_workflow_set_result(\"dummy_knn\") |> \n  autoplot() +\n  labs(title = \"Nearest Neighbors Hyperparameter Search\")                   \n                  \n\nens <- stacks::stacks() %>%\n  stacks::add_candidates(dep_models) %>%\n  stacks::blend_predictions(  metric = metric_set(accuracy),\n      penalty = c(10^seq(-2.7, -0.4, 0.1)),\n      non_negative = TRUE,\n      control = tune::control_grid(allow_par = TRUE))\n\nautoplot(ens)\n\nautoplot(ens, \"weights\")\n\nclassification_fit <- fit_members(ens)                   \n                                \n```\n\n## Feature Importance\n                   \n```{r}\n#| label: explainer\n#| warning: false\n#| message: false\n\n\nexplainer <- \n  explain_tidymodels(\n    classification_fit, \n    data = train_df %>% dplyr::select(all_of(features)), \n    y = as.numeric(train_df$y),\n    label = \"Ensemble\",\n    verbose = FALSE\n  )  %>% \n  model_parts()\n\nggplot_imp <- function(...) {\n  obj <- list(...)\n  metric_name <- attr(obj[[1]], \"loss_name\")\n  metric_lab <- paste(metric_name, \n                      \"after permutations\\n(higher indicates more important)\")\n  \n  full_vip <- bind_rows(obj) %>%\n    filter(variable != \"_baseline_\")\n  \n  perm_vals <- full_vip %>% \n    filter(variable == \"_full_model_\") %>% \n    group_by(label) %>% \n    summarise(dropout_loss = mean(dropout_loss))\n  \n  p <- full_vip %>%\n    filter(variable != \"_full_model_\") %>% \n    mutate(variable = fct_reorder(variable, -dropout_loss)) %>%\n    ggplot(aes(dropout_loss, variable)) \n  \n  if(length(obj) > 1) {\n    p <- p + \n      facet_wrap(vars(label)) +\n      geom_vline(data = perm_vals, aes(xintercept = dropout_loss, color = label),\n                 linewidth = 1.4, lty = 2, alpha = 0.7) +\n      geom_boxplot(aes(color = label, fill = label), alpha = 0.2)\n  } else {\n    p <- p + \n      geom_vline(data = perm_vals, aes(xintercept = dropout_loss),\n                 linewidth = 1.4, lty = 2, alpha = 0.7) +\n      geom_boxplot(fill = \"#91CBD765\", alpha = 0.4)\n    \n  }\n  p +\n    theme(legend.position = \"none\") +\n    labs(x = metric_lab, \n         y = NULL,  fill = NULL,  color = NULL)\n}\n                   \nggplot_imp(explainer)      \n                   \n\n``` \n\n\n## Model Calibration\n\n```{r}\n#| label: calibration\n#| warning: false\n#| message: false                   \n\npreds_prob = augment(classification_fit, \n                     new_data = competition_df, \n                     type = \"prob\")\n\npreds_prob |> \n  ggplot(aes(x = .pred_1)) +\n           geom_dotplot(binwidth = 0.01)+\n  labs(\n    title = \"Bank y Predictions Distribution on full test set\",\n    caption = \"Data source: Kaggle.com | Visual: Jim Gruman\",\n    x = \"Outcome\",\n    y = NULL,\n    fill = \"Class\"\n  )\n\nthreshold_data <- predict(classification_fit, train_df, type = \"prob\") |> \n   bind_cols(train_df) |> \n   threshold_perf(y, .pred_1, thresholds = seq(0.5, 1, by = 0.0025)) |>\n   filter(.metric != \"distance\") |>\n   mutate(group = case_when(\n    .metric == \"sens\" | .metric == \"spec\" ~ \"1\",\n    TRUE ~ \"2\"\n   ))\n\nmax_j_index_threshold <- threshold_data |>\n  filter(.metric == \"j_index\") |>\n  dplyr::slice_max(order_by = .estimate, n = 1) |>\n  pull(.threshold)\n\nggplot(threshold_data, aes(x = .threshold, y = .estimate, color = .metric, alpha = group)) +\n  geom_line() +\n  theme_minimal() +\n  scale_color_viridis_d(end = 0.9) +\n  scale_alpha_manual(values = c(.6, 1), guide = \"none\") +\n  geom_vline(xintercept = max_j_index_threshold, alpha = .6, color = \"grey30\") +\n  labs(\n    x = \"'Good' Threshold\\n(above this value is considered 'good')\",\n    y = \"Metric Estimate\",\n    title = \"Balancing performance by varying the threshold\",\n    subtitle = \"Sensitivity or specificity alone might not be enough!\\nVertical line = Max J-Index\"\n  )\n\nmax_j_index_threshold[1]\n\n```\n\n\n\n\n# Submission\n             \n\n```{r }                   \n#| label: submission\n#| warning: false\n#| message: false\n\npredict(classification_fit, train_df, type = \"prob\") %>% \n  bind_cols(train_df) |> \n  mutate(\n    .pred_class = make_two_class_pred(\n      estimate = .pred_1,\n      levels = levels(y),\n#      threshold = 0.5\n      threshold = max_j_index_threshold[1]\n    )\n  ) |>                    \n  conf_mat(y, .pred_class) %>%\n  yardstick:::autoplot.conf_mat(type = \"heatmap\") +\n  scale_fill_distiller(palette = \"RdPu\")\n\nsubmit_df <- preds_prob |> \n  transmute(\n    id,\n    y= if_else(.pred_1 > max_j_index_threshold[1],\n                         # .pred_Extrovert > 0.5,\n                          \"Extrovert\",\n                          \"Introvert\")\n  )\n\nhead(submit_df)  %>% \n     knitr::kable()      \n\nsubmit_df  %>% \n  write_csv(\"submission.csv\")\n```  ","metadata":{"_uuid":"58eb6155-c79a-41a6-bc8f-f5ec777fc482","_cell_guid":"a12f954c-f2b2-48b8-b95d-d8ce191d800b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}