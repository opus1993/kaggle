---
title: "Mental Health"
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: cosmo
    highlight: tango
    code_folding: hide
---
  
# Introduction  {.tabset .tabset-fade .tabset-pills}

The goal of this competition is to build classification models to predict depression.

My notebook serves as a demonstration of some of the possible techniques available to arrive at a solution.  I intend to add to this as I have time available. Your questions and comments are welcome.

If you fork this on kaggle, be sure to choose the kernel Environment setting for "Always use latest environment"

Lets dive right in.

The Kaggle kernels have many of the common r packages built in.  

![](https://www.rexulti.com/sites/g/files/qhldwo9576/files/styles/500x300_2x/public/Image-min%20%285%29.png?h=abc34b67&itok=DHCSxa9T)

## Load libraries

In addition to `tidymodels` we will load the `bonsai` interface to lightgbm.

```{r }
#| label: setup
#| warning: false
#| message: false

if (dir.exists("/kaggle")){
  path <- "/kaggle/input/playground-series-s4e11/"
  orig_path <- "/datasets/sumansharmadataworld/depression-surveydataset-for-analysis"
    
options(repos = c(CRAN = "https://packagemanager.posit.co/cran/2021-03-22"))
#install.packages("BradleyTerry2", quiet = TRUE)
# remotes::install_github("luisdva/hexsession", quiet = TRUE)  had used previously, but recent addition of menu() makes it unworkable here

cores <- future::availableCores()

} else {
  path <- stringr::str_c(here::here("data"),"/")
  orig_path <- stringr::str_c(here::here("data"),"/")

  cores <- future::availableCores(omit = 7)
}
 
suppressPackageStartupMessages({
library(tidyverse, quietly = TRUE) # metapackage of all tidyverse packages
library(tidymodels) # metapackage see https://www.tidymodels.org/
  
library(discrim)  
library(baguette)  
  
library(bonsai)  
library(stacks)
 # interface to lightgbm

})

tidymodels_prefer()

options(tidymodels.dark = TRUE)

theme_set(ggdark::dark_theme_minimal())

```

## Load Data

Two features identified by @Leanaz in kernel [pgs4e11-eda-basic-data-cleaning-in-r](https://www.kaggle.com/code/leanaz/pgs4e11-eda-basic-data-cleaning-in-r)

```{r }
#| label: load data
#| warning: false
#| message: false


train_spec <- cols(
  id = col_double(),
  Name = col_character(),
  Gender = col_character(),
  Age = col_double(),
  City = col_character(),
  `Working Professional or Student` = col_character(),
  Profession = col_character(),
  `Academic Pressure` = col_double(),
  `Work Pressure` = col_double(),
  CGPA = col_double(),
  `Study Satisfaction` = col_double(),
  `Job Satisfaction` = col_double(),
  `Sleep Duration` = col_character(),
  `Dietary Habits` = col_character(),
  Degree = col_character(),
  `Have you ever had suicidal thoughts ?` = col_character(),
  `Work/Study Hours` = col_double(),
  `Financial Stress` = col_character(),
  `Family History of Mental Illness` = col_character(),
  Depression = readr::col_factor()
)


competition_spec <- cols(
  id = col_double(),
  Name = col_character(),
  Gender = col_character(),
  Age = col_double(),
  City = col_character(),
  `Working Professional or Student` = col_character(),
  Profession = col_character(),
  `Academic Pressure` = col_double(),
  `Work Pressure` = col_double(),
  CGPA = col_double(),
  `Study Satisfaction` = col_double(),
  `Job Satisfaction` = col_double(),
  `Sleep Duration` = col_character(),
  `Dietary Habits` = col_character(),
  Degree = col_character(),
  `Have you ever had suicidal thoughts ?` = col_character(),
  `Work/Study Hours` = col_double(),
  `Financial Stress` = col_character(),
  `Family History of Mental Illness` = col_character(),
)


preprocessor <- function(dataframe) {

dataframe <- dataframe %>%
    janitor::clean_names() |>
    
    mutate(across(c(where(is.numeric), -id), ~ as.factor(.x), .names = "factor_{.col}")) |>
    mutate(across(c(profession, name), \(x) if_else(is.na(x), TRUE, FALSE), .names = "missing_{.col}" )) %>% 
    
    # features identified by Leanaz in kernel [pgs4e11-eda-basic-data-cleaning-in-r](https://www.kaggle.com/code/leanaz/pgs4e11-eda-basic-data-cleaning-in-r)
    mutate(coalesce_pressure = coalesce(factor_work_pressure, factor_academic_pressure))  |>

    mutate(across(c(where(is.character)), ~ as.factor(.x))) 

return(dataframe)
}

#origin_df <-read_csv(str_c(orig_path, "final_depression_dataset_1.csv"),
#                     col_types = train_spec,
#                     show_col_types = FALSE) %>% 
#     mutate(Depression = factor(if_else(Depression=="Yes",1,0)))

raw_df <- read_csv(str_c(path, "train.csv"),
                   col_types = train_spec,
                   show_col_types = FALSE) %>%
 #         bind_rows(origin_df) %>% 
          preprocessor() 

tst_df <- read_csv(str_c(path, "test.csv"),
                   col_types = competition_spec,
                   show_col_types = FALSE)  %>% 
  preprocessor() 

# because we already know the test set, let's remove the train set factor levels that do not correspond with anything on the test set
for (col in names(raw_df)) {
    if (is.factor(raw_df[[col]]) & col != "depression") {
      # Get levels in train and test dataframes
      raw_levels <- levels(raw_df[[col]])
      tst_levels <- levels(tst_df[[col]])
      
      # Identify levels in train not in test
      new_levels <- setdiff(raw_levels, tst_levels)
      
      # Set these levels to NA in train dataframe
      raw_df[[col]] <- factor(raw_df[[col]], levels = c(tst_levels, new_levels))
      raw_df[[col]][raw_df[[col]] %in% new_levels] <- NA_character_
    }
  }

# the synthetic playground competitions seem to perform better when numerics are also included as factors
all_df <-
    bind_rows(raw_df %>% mutate(source = "train"),
              tst_df %>% mutate(source = "test")) # |>   
 #   mutate(missing_flag = case_when(
 #     is.na(factor_cgpa) ~ TRUE,
 #     is.na(study_satisfaction) ~ TRUE,
 #     is.na(academic_pressure) ~ TRUE,
 #     .default = FALSE
 #   ))


train_df <- all_df %>% 
  filter(source == "train") %>% 
  select(-source) 

competition_df <- all_df %>% 
  filter(source == "test") %>% 
  select(-source, -depression)

features <- train_df %>%
  select(-id, -depression, -study_satisfaction, -factor_study_satisfaction, -factor_work_pressure, -factor_job_satisfaction, -factor_academic_pressure, -working_professional_or_student) %>%
  names()

train_df <- train_df %>% 
  distinct(pick(all_of(features)), .keep_all = TRUE)

nom_features <- train_df %>%
  select(all_of(features)) %>%
  select(where(is.character), where(is.factor)) %>%
  names() 

logical_features <- train_df %>%
  select(all_of(features)) %>%
  select(where(is.logical)) %>%
  names() 

num_features <- train_df %>%
  select(all_of(features)) %>%
  select(where(is.numeric)) %>%
  names()


```

Nominal features:

`r nom_features`

Numeric features: 

`r num_features`

Logical features: 

`r logical_features`


Size of the combined train and competition datasets:

`r nrow(all_df)`

Size of the split made available to machine learning

`r nrow(train_df)`


# EDA {.tabset .tabset-fade .tabset-pills}

## Numeric features

Consider where features require univariate transformation, or clipping outliers.
```{r}
#| label: numeric
#| warning: false
#| message: false
#| fig.height: 6
#| fig.width: 6

train_df %>% 
  select(all_of(num_features), depression ) %>% 
  pivot_longer(-depression,
    names_to = "metric",
    values_to = "value"
  ) %>%
  ggplot(aes(value, fill = depression)) +
  geom_histogram(show.legend = FALSE, bins = 200) +
   facet_wrap(vars(metric), scales = "free", ncol = 2) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.title.position = "plot") +
  labs(color = NULL, fill = "Loan Status",
       title = "Numeric Feature Univariate Distributions",
       caption = "Data: Kaggle.com | Visual: Jim Gruman")

```


## Nominal features

Explore the distribution of outcome class by factor level, and the factor levels that exist in test that do not exist in training.


```{r}
#| label: nominal
#| warning: false
#| message: false
#| fig.height: 24
#| fig.width: 12


if(length(nom_features) >0){

train_df %>% 
  select(all_of(nom_features), depression) %>% 
  mutate(across(nom_features, fct_lump_n,n = 10, other_level = 'other')) %>%
  pivot_longer(-depression,
    names_to = "metric",
    values_to = "value"
  ) %>%
    
  summarise(n = n(),
            .by = c(depression, metric, value)) %>%
      
  mutate(value = tidytext::reorder_within(value, n, metric)) %>%
    
  ggplot(aes(x = n, y = value, fill = depression)) +
  geom_col(aes(x = n)) +
  
  tidytext::scale_y_reordered() +
  scale_x_continuous(n.breaks = 3, guide = guide_axis(n.dodge = 2))  +
  facet_wrap(vars(metric), scales = "free", ncol = 3) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
       legend.position = "bottom") +
  labs(title = "Nominal Feature Counts",
       fill = NULL,
       caption = "Data: Kaggle | Visual: Jim Gruman")
  
}

if(length(nom_features) >0){
    
train_df %>% 
  select(all_of(nom_features), depression) %>% 
  mutate(across(nom_features, fct_lump_n,n = 10, other_level = 'other')) %>%

  pivot_longer(-depression,
    names_to = "metric",
    values_to = "value"
  ) %>%
    
  summarise(n = n(),
            .by = c(depression, metric, value)) %>%

  mutate(value = tidytext::reorder_within(value, n, metric)) %>%
    
  ggplot(aes(x = n, y = value, fill = depression)) +
  geom_col(position = "fill") +

  tidytext::scale_y_reordered() +
  scale_x_continuous(n.breaks = 3, guide = guide_axis(n.dodge = 2))  +
  facet_wrap(vars(metric), scales = "free", ncol = 3) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
       legend.position = "bottom") +
  labs(title = "Proportion of Outcome in Nominal Feature Counts",
       fill = NULL,
       caption = "Data: Kaggle | Visual: Jim Gruman")    

}

```

## Logical features

```{r}
#| label: logical
#| warning: false
#| message: false
#| fig.height: 6
#| fig.width: 6


if(length(logical_features) >0){

train_df %>% 
  select(all_of(logical_features), depression) %>% 
  pivot_longer(-depression,
    names_to = "metric",
    values_to = "value"
  ) %>%
  ggplot(aes(y = value, fill = depression)) +
  geom_bar() +
  scale_x_continuous(n.breaks = 3, guide = guide_axis(n.dodge = 2)) +
   facet_wrap(vars(metric), scales = "free", ncol = 2) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
       legend.position = "bottom") +
  labs(title = "Logical Feature Counts",
       fill = "Outcome",
       caption = "Data: Kaggle.com | Visual: Jim Gruman")
}

```

## Counts of Missingness
                  
```{r}
#| label: counts of missingness

train_df %>% 
  summarize(across(all_of(features), function(x) sum(is.na(x)))) %>% 
  pivot_longer(everything(),
              names_to = "feature",
              values_to = "Count of Missing") %>% 
                   knitr::kable()
                   
train_df %>% 
    select(all_of(features)) %>%
    slice_sample(n = 2000) %>%
    naniar::vis_miss()          

naniar::gg_miss_var(train_df %>% select(all_of(features), depression), 
                   facet = depression)    

# summary(arsenal::comparedf(train_df, competition_df))

```

## Counts of Distinct
                   
This dataset has quite a few unusual factor levels. And more important, there are factor levels in test that do not appear in train.
               
```{r}
#| label: counts of distinct
               
train_df %>%
  summarize(across(all_of(features), n_distinct)) %>%
  pivot_longer(everything(), names_to = "feature", values_to = "Count of distinct train") |>
  left_join(
    competition_df %>%
      summarize(across(all_of(features), n_distinct)) %>%
      pivot_longer(everything(), names_to = "feature", values_to = "Count of distinct test")
  ) %>% 
                   knitr::kable()
               
```

## Duplicated

Is this competition transaction already in the training data with a correct label?

```{r}
#| label: duplicates
#| warning: false
#| message: false
all_df %>%
    group_by_at(features) %>%
    mutate(num_dups = n(),
           dup_id = row_number()) %>% 
    ungroup() %>%
    group_by(source) %>%
    mutate(is_duplicated = dup_id > 1) %>% 
    count(is_duplicated) %>% 
                   knitr::kable()
               

```
                   



## Target

```{r}
#| label: outcome 
#| warning: false
#| message: false
#| fig.width: 6



train_df %>%
  summarize(outcome_sum = n(), .by = depression) %>%
  arrange(outcome_sum) %>%
  mutate(prop = outcome_sum / nrow(train_df)) %>%
  mutate(ypos = cumsum(prop) - 0.5 * prop) %>%
  ggplot(aes(x = "", y = prop, fill = depression)) +
  geom_bar(stat = "identity",
           width = 1,
           show.legend = FALSE) +
  geom_text(
    aes(
      y = ypos,
      label = paste0(depression
                     , "\n", round(prop, 2) * 100, "%")
    ),
    color = "white",
    nudge_x = 0,
    size = 3
  ) +
  coord_polar("y", start = 0) +
  theme(
    axis.text = element_blank(),
    axis.title = element_blank()  ) +
  labs(title = "Depression", caption = "Data: Kaggle.com | Visual: Jim Gruman")

```
                              
           
                
# Machine Learning {.tabset .tabset-fade .tabset-pills}

## Recipe

```{r}
#| label: recipe

base_rec <- recipe(
    
    formula(paste0("depression ~ ", 
               str_c(features,  collapse = " + "))),
    data = train_df
  ) %>% 

  step_novel(all_nominal_predictors())  %>% 
  step_other(all_nominal_predictors(), threshold = 0.05) %>% 
  
  step_ratio(work_pressure, age, denom = denom_vars(job_satisfaction)) %>% 
  step_ratio(cgpa, denom = denom_vars(academic_pressure)) %>% 

  step_zv(all_predictors()) 

                 
imputed_rec <- recipe(
    
    formula(paste0("depression ~ ", 
               str_c(features,  collapse = " + "))),
    data = train_df
  ) %>% 

  step_novel(all_nominal_predictors())  %>% 
  step_other(all_nominal_predictors(), threshold = 0.05) %>% 
  
  step_impute_median(all_numeric_predictors()) %>% 
  step_impute_mode(all_nominal_predictors()) %>% 
  
  step_dummy(all_nominal_predictors()) %>%
  step_integer(all_logical_predictors()) %>% 
  
  step_ratio(work_pressure, age, denom = denom_vars(job_satisfaction)) %>% 
  step_ratio(cgpa, denom = denom_vars(academic_pressure)) %>% 

  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors())

folds <- vfold_cv(train_df, 
                  v = 3,
                  repeats = 3,
                  strata = depression) 
                   
                            
                                     
```



## Earth

```{r}
#| label: earth workflowset
#| warning: false
#| message: false
#| fig.width: 12

bag_mars_earth_spec <-
  bag_mars() %>%
  set_engine('earth') %>%
  set_mode('classification')

discrim_flexible_earth_spec <-
  discrim_flexible(num_terms = tune(), prod_degree = tune(), prune_method = "forward") %>%
  set_engine('earth')

mars_earth_spec <-
  mars(prod_degree = tune()) %>%
  set_engine('earth') %>%
  set_mode('classification')

boost_tree_lgbm_spec <- 
  boost_tree(
    trees = 3e3L,
   tree_depth = 118,
   learn_rate =  0.015,
   min_n = 79,
#   mtry = tune(),
   loss_reduction = 9e-9
  ) %>% 
  set_engine(engine = "lightgbm",
             is_unbalance = TRUE,
             num_leaves = 994,
             num_threads = cores
       #      boosting = "goss"   # this may slow the runtime
             ) %>%
  set_mode(mode = "classification") 

#future::plan("multisession", workers = cores) 


dep_models <- 
   workflow_set(
      preproc = list(imputed = imputed_rec,
                     imputed = imputed_rec,
                     imputed = imputed_rec,
                     base = base_rec),
      models = list(bag = bag_mars_earth_spec, 
                    discrim = discrim_flexible_earth_spec, 
                    mars = mars_earth_spec,
                    lgbm = boost_tree_lgbm_spec),
      cross = FALSE
   ) %>% 
   option_add(
    control = control_stack_grid(),
    metrics = metric_set(mn_log_loss)
  ) %>% 
   workflow_map("tune_grid", resamples = folds, grid = 3, 
                metrics = metric_set(mn_log_loss), verbose = TRUE)

autoplot(dep_models)

autoplot(dep_models, select_best = TRUE)

rank_results(dep_models, rank_metric = "mn_log_loss", select_best = TRUE) %>% 
   select(rank, mean, model, wflow_id, .config)

dep_stack <- stacks() %>%
  add_candidates(dep_models) %>%
  blend_predictions(  metric = metric_set(accuracy),
      penalty = c(10^seq(-1.3, -0.1, 0.1)),
      non_negative = TRUE,
      control = tune::control_grid(allow_par = TRUE))

autoplot(dep_stack)

autoplot(dep_stack, type = "weights")

classification_fit <- dep_stack %>% 
    fit_members()


```

# Performance {.tabset .tabset-fade .tabset-pills}

## Submission
```{r }                   
#| label: importance
#| warning: false
#| message: false
                   
augment(classification_fit, train_df) %>% 
  conf_mat(depression, .pred_class) %>%
  yardstick:::autoplot.conf_mat(type = "heatmap")

submit_df <-  augment(classification_fit , competition_df) %>%
       select(id, Depression = .pred_class)

head(submit_df)  %>% 
     knitr::kable()      

submit_df  %>% 
  write_csv("submission.csv")
```  