{"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"sourceType":"competition"}],"dockerImageVersionId":30749,"isInternetEnabled":true,"language":"rmarkdown","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jimgruman/keep-it-classy?scriptVersionId=272737832\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"---\ntitle: \"Bank Loan Payback\"\ndate: '`r Sys.Date()`'\noutput:\n  html_document:\n    number_sections: true\n    fig_caption: true\n    toc: true\n    fig_width: 7\n    fig_height: 4.5\n    theme: cosmo\n    highlight: tango\n    code_folding: hide\n---\n  \n# Introduction  {.tabset .tabset-fade .tabset-pills}\n\nThe goal of this competition is to predict the crop yield.\n\nMy notebook serves as a demonstration of some of the possible techniques available to arrive at a solution.  I intend to add to this as I have time available. Your questions and comments are welcome.\n\nLets dive right in.\n\nThe Kaggle kernels have many of the common r packages built in.  \n\n## Load libraries\n\n```{r }\n#| label: setup\n#| warning: false\n#| message: false\n\nif (dir.exists(\"/kaggle\")){\n  path <- \"/kaggle/input/playground-series-s5e11/\"\n    \n# options(repos = c(CRAN = \"https://packagemanager.posit.co/cran/2021-03-22\"))\n\ninstall.packages(\"pak\")\npak::pak(\"bonsai\")\n\nremotes::install_github(\"luisdva/hexsession\", quiet = TRUE)    \n#remotes::install_github(\"tidymodels/plsmod\", quiet = TRUE)    \nremotes::install_url('https://github.com/catboost/catboost/releases/download/v1.2.8/catboost-R-linux-x86_64-1.2.8.tgz', \n                     INSTALL_opts = c(\"--no-multiarch\", \"--no-test-load\"),\n                    quiet = TRUE)  \n\ncores <- future::availableCores()\n\n} else {\n  path <- stringr::str_c(here::here(\"data\"),\"/\")\n  orig_path <- stringr::str_c(here::here(\"data\"),\"/\")\n\n  cores <- future::availableCores(omit = 2)\n}\n \nsuppressPackageStartupMessages({\nlibrary(tidyverse, quietly = TRUE) # metapackage of all tidyverse packages\nlibrary(tidymodels, quietly = TRUE) # metapackage see https://www.tidymodels.org/\n    \nlibrary(bonsai)  # Tidymodels access to Catboost\nlibrary(catboost)\nlibrary(stacks)  # Tidymodels ensembling\n    \nlibrary(DALEXtra) # Tidymodels Explainability         \n\n})\n\ntidymodels_prefer()\n\noptions(tidymodels.dark = TRUE)\n\ntheme_set(theme_minimal())\n\nhexsession::make_tile(packages = c(\"DALEXtra\", \"DALEX\", \"catboost\",\"bonsai\",\"correlationfunnel\",\"yardstick\",\"workflows\",\n                                   \"tune\",\"rsample\",\"recipes\",\"parsnip\",\"infer\",\"dials\",\"broom\",\"tidymodels\",\"lubridate\",\n                                   \"forcats\",\"stringr\",\"dplyr\",\"purrr\",\"readr\",\"tidyr\",\"tibble\",\"ggplot2\",\"tidyverse\",\"reprex\",\"testthat\",\"usethis\"))\n\n\n```\n\n\n\n## Load Data\n\n```{r }\n#| label: load data\n#| warning: false\n#| message: false\n\nalphabet_lookup <- setNames(1:26, LETTERS)\n\npreprocessor <- function(dataframe) {\n\ndataframe <- dataframe |>\n    janitor::clean_names() |>\n    \n    mutate(loan_to_income = loan_amount / annual_income,\n          total_debt = debt_to_income_ratio / annual_income ,\n          available_income = annual_income / debt_to_income_ratio,\n          affordability = available_income / loan_amount,\n          risk_score = debt_to_income_ratio *40 + (1 - credit_score/850)*30 + interest_rate ^2,\n          grade_number = as.integer(str_sub(grade_subgrade, 2,2)),\n          grade_combined = alphabet_lookup[str_sub(grade_subgrade, 1, 1)]*10 + grade_number,\n          credit_interest = credit_score * interest_rate / 100,\n          income_credit = log1p(annual_income) * credit_score / 100,\n          debt_loan = debt_to_income_ratio / log1p(loan_amount),\n          log_income = log1p(annual_income),\n          log_loan = log1p(loan_amount)\n   ) |> \n    mutate(across(c(where(is.character)), ~ as.factor(.x))) \n\nreturn(dataframe)\n}\n\nraw_df <- read_csv(str_c(path, \"train.csv\"),\n                   show_col_types = FALSE) \n\ntst_df <- read_csv(str_c(path, \"test.csv\"),\n                   show_col_types = FALSE)  \n\nall_df <-\n    bind_rows(raw_df %>% mutate(source = \"train\"),\n              tst_df %>% mutate(source = \"test\")) |>\n          preprocessor() |> \n   mutate(loan_paid_back = factor(loan_paid_back))\n\ntrain_df <- all_df %>% \n  filter(source == \"train\") %>% \n  select(-source) \n\ncompetition_df <- all_df %>% \n  filter(source == \"test\") %>% \n  select(-source, -loan_paid_back)\n\n\n```\n\n# EDA {.tabset .tabset-fade .tabset-pills}\n\n## Features\n\nWe will de-duplicate the training set and calculate a mean loan_paid_back figure.\n\n```{r}\n#| label: Features\n#| warning: false\n#| message: false\n#| fig.width: 6\n\nconflicted::conflict_prefer(\"select\", \"dplyr\")\nconflicted::conflict_prefer(\"where\", \"dplyr\")\n\nfeatures <- train_df %>%\n  dplyr::select(-id, -loan_paid_back) |> \n  names()\n\ntrain_df <- train_df %>% \n  dplyr::group_by_at(all_of(features)) |> \n  dplyr::summarise(id = min(id),\n            loan_paid_back = first(loan_paid_back),\n            .groups = \"drop\")\n\nnom_features <- train_df |> \n  dplyr::select(dplyr::all_of(features)) |> \n  dplyr::select(dplyr::where(is.factor)) |> \n  names() \n\nlogical_features <- train_df |> \n  dplyr::select(dplyr::all_of(features)) |> \n  dplyr::select(dplyr::where(is.logical)) |> \n  names() \n\nnum_features <- train_df |> \n  dplyr::select(dplyr::all_of(features)) |> \n  dplyr::select(dplyr::where(is.numeric)) |> \n  names()\n```\n\nNominal features:\n\n`r nom_features`\n\nNumeric features: \n\n`r num_features`\n\nLogical features: \n\n`r logical_features`\n\n\nSize of the combined train and competition datasets:\n\n`r nrow(all_df)`\n\nSize of training set after de-duplication\n\n`r nrow(train_df)`\n\n\n## Numeric features\n\n\n\n```{r}\n#| label: numeric\n#| warning: false\n#| message: false\n#| fig.height: 9\n\ntrain_df %>% \n  dplyr::select(all_of(num_features), loan_paid_back ) %>% \n  pivot_longer(-loan_paid_back,\n    names_to = \"metric\",\n    values_to = \"value\"\n  ) %>%\n  ggplot(aes(value, fill = loan_paid_back)) +\n  geom_density(position = \"stack\") +\n  scale_fill_brewer(type = \"seq\", palette = \"Greens\") +\n  facet_wrap(vars(metric), scales = \"free\", ncol = 2) +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = \"top\") +\n  labs(color = NULL, fill = \"loan_paid_back\",\n       title = \"Numeric Feature Univariate Distributions\",\n       caption = \"Data: Kaggle | Visual: Jim Gruman\")\n\n```\n\n\n## Nominal and Logical features\n\nExplore the distribution of outcome class by factor level.\n\n\n```{r}\n#| label: nominal\n#| warning: false\n#| message: false\n#| fig.height: 6\n#| fig.width: 6\n\n\nif(length(nom_features) >0){\n\ntrain_df %>% \n  select(all_of(nom_features), all_of(logical_features), loan_paid_back) %>% \n  mutate(across(nom_features, fct_lump_n,n = 10, other_level = 'other'),\n         across(logical_features, \\(x) factor(x))) %>%\n  pivot_longer(-loan_paid_back,\n    names_to = \"metric\",\n    values_to = \"value\"\n  ) %>%\n    \n  filter(!is.na(loan_paid_back)) %>% \n    \n  summarise(n = n(),\n            .by = c(loan_paid_back, metric, value)) %>%\n      \n  mutate(value = tidytext::reorder_within(value, n, metric)) %>%\n    \n  ggplot(aes(x = n, y = value, fill = loan_paid_back)) +\n  geom_col() +\n  tidytext::scale_y_reordered() +\n  scale_x_continuous(n.breaks = 3, guide = guide_axis(n.dodge = 2))  +\n  scale_fill_brewer(type = \"seq\", palette = \"Greens\") +\n  facet_wrap(vars(metric), scales = \"free\", ncol = 2) +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n       legend.position = \"bottom\") +\n  labs(title = \"Nominal Feature Counts\",\n       fill = NULL, y = NULL,\n       caption = \"Data: Kaggle | Visual: Jim Gruman\")\n\n}\n\n```\n\n## Counts of Missingness\n\n                  \n```{r}\n#| label: counts of missingness\n\ntrain_df %>% \n  summarize(across(all_of(features), function(x) sum(is.na(x)))) %>% \n  pivot_longer(everything(),\n              names_to = \"feature\",\n              values_to = \"Count of Missing\") %>% \n                   knitr::kable()\n\ncompetition_df %>% \n  summarize(across(all_of(features), function(x) sum(is.na(x)))) %>% \n  pivot_longer(everything(),\n              names_to = \"feature\",\n              values_to = \"Count of Missing\") %>% \n                   knitr::kable()\n\n```\n\n## Counts of Distinct\n                   \n               \n```{r}\n#| label: counts of distinct\n               \ntrain_df %>%\n  summarize(across(all_of(features), n_distinct)) %>%\n  pivot_longer(everything(), names_to = \"feature\", values_to = \"Count of distinct train\") |>\n  left_join(\n    competition_df %>%\n      summarize(across(all_of(features), n_distinct)) %>%\n      pivot_longer(everything(), names_to = \"feature\", values_to = \"Count of distinct test\"),\n    by = join_by(feature)\n  ) %>% \n                   knitr::kable()\n               \n```\n\n## Duplicated\n\nIs this competition transaction already in the training data with a correct label?\n\n\n```{r}\n#| label: duplicates\n#| warning: false\n#| message: false\n\nbind_rows(train_df %>% mutate(source = \"train\"),\n              competition_df %>% mutate(source = \"test\")) |> \n    group_by_at(features) %>%\n    mutate(num_dups = n(),\n           dup_id = row_number()) %>% \n    ungroup() %>% \n    group_by(source) %>%\n    mutate(is_duplicated = dup_id > 1) %>% \n    count(is_duplicated) %>% \n                   knitr::kable()\n\n\n\n```\n\n\n## Pairwise Correlations\n                   \n`ggcorrplot` provides a quick look at numeric features where the correlation may be significant. \n\n```{r}\n#| label: pairwise correlations\n#| fig.width: 9\n#| fig.height: 9                 \n                 \ntrainp.mat <- train_df %>% \n  mutate(loan_paid_back = as.numeric(loan_paid_back)) |> \n  select(all_of(num_features), loan_paid_back) %>% \n  ggcorrplot::cor_pmat() \n                   \ntrain_df %>% \n  mutate(loan_paid_back = as.numeric(loan_paid_back)) |> \n  select(all_of(num_features), loan_paid_back) %>%                    \n  cor() %>% \n  ggcorrplot::ggcorrplot(hc.order = TRUE, \n                         lab = TRUE,\n                         p.mat = trainp.mat,\n    type = \"lower\", insig = \"blank\") +\n  labs(title = \"Pairwise Correlations Training Set\")\n                   \ncompetitionp.mat <- competition_df %>% \n  select(all_of(num_features)) %>% \n  ggcorrplot::cor_pmat() \n                   \ncompetition_df %>% \n  select(all_of(num_features)) %>%                   \n  cor()   %>% \n  ggcorrplot::ggcorrplot(hc.order = TRUE, lab = TRUE,\n                         p.mat = competitionp.mat,\n    type = \"lower\", insig = \"blank\") +\n  labs(title = \"Pairwise Correlations Competition Set\")\n\n```                    \n               \n                   \n## Target\n\n```{r}\n#| label: outcome \n#| warning: false\n#| message: false\n#| fig.width: 6\n\n\ntrain_df %>%\n  summarize(outcome_sum = n(), .by = loan_paid_back) %>%\n  arrange(desc(outcome_sum)) %>%\n  mutate(prop = outcome_sum / nrow(train_df)) %>%\n  mutate(ypos = cumsum(prop) - 0.5 * prop) %>%\n  ggplot(aes(x = \"\", y = prop, fill = loan_paid_back)) +\n  geom_bar(stat = \"identity\",\n           width = 1,\n           show.legend = FALSE) +\n  geom_text(\n    aes(\n      y = ypos,\n      label= paste0(loan_paid_back\n                     , \"\\n\", round(prop, 2) * 100, \"%\")\n    ),\n    color = \"white\",\n    nudge_x = 0,\n    size = 3\n  ) +\n  scale_fill_brewer(type = \"qual\", palette = \"Dark2\") +                   \n  coord_polar(\"y\", start = 0) +\n  theme(\n    axis.text = element_blank(),\n    axis.title = element_blank()  ) +\n  labs(title = \"loan_paid_back\", caption = \"Data: Kaggle.com | Visual: Jim Gruman\")\n\n``` \n                \n# Regression Machine Learning {.tabset .tabset-fade .tabset-pills}\n\n\n## Recipe\n\n```{r}\n#| label: recipe\n#| warning: false\n#| message: false\n#| fig.width: 6\n                   \ncatboost_rec <- recipe(formula(paste0(\"loan_paid_back ~ \", str_c(features, collapse = \" + \"))), data = train_df) \n                   \n```\n\n\n## Catboost \n\n\n```{r}\n#| label: catboost \n#| warning: false\n#| message: false\n\nboost_tree_catboost_spec <- \n  boost_tree(\n    trees = 2900,\n    tree_depth = 12,\n    learn_rate =  .03,\n    stop_iter = 100\n  ) %>% \n  set_engine(engine = \"catboost\" ,\n             thread_count = cores,\n             eval_metric = \"AUC\",\n             loss_function =  \"Logloss\",\n         #    early_stopping_rounds = 100,\n             bagging_temperature = 1,    # default is 1.0\n             l2_leaf_reg = 3.0) %>%  #3.0 is the default. Any positive number is allowed.\n  set_mode(mode = \"classification\") \n\nclassification_fit <- fit(workflow(catboost_rec, boost_tree_catboost_spec), train_df) \n\naugment(classification_fit, train_df) |> \n  roc_auc(loan_paid_back, .pred_0)\n                   \n\n```\n\n\n\n# Performance {.tabset .tabset-fade .tabset-pills}\n\n```{r}\n#| label: explainer\n#| warning: false\n#| message: false\n#| fig.height: 12\n                   \nparsnip::extract_fit_engine(classification_fit) |> \n  catboost::catboost.get_feature_importance() |> \n  as_tibble(rownames = \"feature\") |> \n  mutate(feature = fct_reorder(feature, V1)) |> \n  ggplot(aes(V1, feature)) + \n  geom_col() +\n  labs(title = \"Catboost Gain Importance\")              \n\n```                      \n\n\n                   \n# Submission\n                   \n\n```{r}\n#| label: submission\n#| warning: false\n#| message: false\n#| fig.height: 6\n#| fig.width: 6   \n                 \npredict(classification_fit, train_df, type = \"prob\") %>% \n  bind_cols(train_df) |> \n  mutate(\n    .pred_class = factor(if_else(.pred_1 > 0.5, \"1\",\"0\"))\n  ) |>                    \n  conf_mat(loan_paid_back, .pred_class) %>%\n  yardstick:::autoplot.conf_mat(type = \"heatmap\") +\n  scale_fill_distiller(palette = \"RdPu\")\n\nsubmit_df <- predict(classification_fit, competition_df, type = \"prob\") |>\n  bind_cols(competition_df) |>\n  transmute(\n    id,\n    loan_paid_back = .pred_1)\n\n\nhead(submit_df)  %>% \n     knitr::kable()      \n\nsubmit_df  %>% \n  write_csv(\"submission.csv\")\n```    ","metadata":{"_uuid":"40b52dee-ea49-4c93-87b6-583e49959c7b","_cell_guid":"d32589f7-913c-41f5-a221-405ac167a65a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}