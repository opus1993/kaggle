{"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73291,"databundleVersionId":8930475,"sourceType":"competition"}],"dockerImageVersionId":30618,"isInternetEnabled":true,"language":"rmarkdown","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"---\ntitle: \"Bundle Home and Auto Insurance\"\ndate: '`r Sys.Date()`'\noutput:\n  html_document:\n    number_sections: true\n    fig_caption: true\n    toc: true\n    fig_width: 7\n    fig_height: 4.5\n    theme: cosmo\n    highlight: tango\n    code_folding: hide\n---\n  \n# Introduction  {.tabset .tabset-fade .tabset-pills}\n\nThe goal of this competition is to build classification models to predict which customers respond positively to an automobile insurance offer.\n\nMy notebook serves as a demonstration of some of the possible techniques available to arrive at a solution.  I intend to add to this as I have time available. Your questions and comments are welcome.\n\nIf you fork this on kaggle, be sure to choose the kernel Environment setting for \"Always use latest environment\"\n\nLets dive right in.\n\nThe Kaggle kernels have many of the common r packages built in.  \n\n## Load libraries\n\nIn addition to `tidymodels` we will load the `bonsai` interface to lightgbm.\n\n```{r }\n#| label: setup\n#| warning: false\n#| message: false\n\nif (dir.exists(\"/kaggle\")){\n  path <- \"/kaggle/input/playground-series-s4e7/\"\n\noptions(repos = c(CRAN = \"https://packagemanager.posit.co/cran/2021-03-22\"))\ninstall.packages(\"vip\", quiet = TRUE)\n    \ncores <- future::availableCores()\n\n} else {\n  path <- stringr::str_c(here::here(\"data\"),\"/\")\n\ncores <- future::availableCores(omit = 1)\n}\n\n \nsuppressPackageStartupMessages({\nlibrary(tidyverse, quietly = TRUE) # metapackage of all tidyverse packages\nlibrary(tidymodels) # metapackage see https://www.tidymodels.org/\nlibrary(bonsai)\n})\n\ntidymodels_prefer()\n\noptions(tidymodels.dark = TRUE)\n\ntheme_set(cowplot::theme_minimal_grid())\n\n```\n\n\n## Load Data\n\n```{r }\n#| label: load data\n#| warning: false\n#| message: false\n\n\ntrain_spec <- cols(\n  id = col_double(),\n  Gender = col_character(),\n  Age = col_double(),\n  Driving_License = col_character(),\n  Region_Code = col_double(),\n  Previously_Insured = col_character(),\n  Vehicle_Age = col_character(),\n  Vehicle_Damage = col_character(),\n  Annual_Premium = col_double(),\n  Policy_Sales_Channel = col_double(),\n  Vintage = col_double(),\n  Response = col_character()\n)\n\n\ncompetition_spec <- cols(\n  id = col_double(),\n  Gender = col_character(),\n  Age = col_double(),\n  Driving_License =col_character(),\n  Region_Code = col_double(),\n  Previously_Insured = col_character(),\n  Vehicle_Age = col_character(),\n  Vehicle_Damage = col_character(),\n  Annual_Premium = col_double(),\n  Policy_Sales_Channel = col_double(),\n  Vintage = col_double()\n)\n\n\n\npreprocessor <- function(dataframe) {\n\ndataframe <- dataframe %>%\n    janitor::clean_names() %>%\n\n    mutate(annual_premium = log(round(annual_premium/1000)*1000)) %>% \n    mutate(age = round(age/10)*10) %>% \n    \n    mutate(region_code = round(region_code)) %>% \n    mutate(region_code = factor(region_code)) %>% \n    mutate(policy_sales_channel = factor(policy_sales_channel)) %>% \n    mutate(across(c(where(is.character)), ~ as.factor(.x))) \n\nreturn(dataframe)\n}\n\nraw_df <- read_csv(str_c(path, \"train.csv\"),\n                   col_types = train_spec,\n                   show_col_types = FALSE) %>%\n          preprocessor() \n\ncompetition_df <- read_csv(str_c(path, \"test.csv\"),\n                   col_types = competition_spec,\n                   show_col_types = FALSE)  %>% \n  preprocessor() \n\nall_df <-\n    bind_rows(raw_df %>% mutate(source = \"train\"),\n            competition_df %>% mutate(source = \"test\"))\n\ntrain_df <- all_df %>% \n  filter(source == \"train\") %>% \n  select(-source) %>%\n  mutate(response = factor(response))\n\ncompetition_df <- all_df %>% \n  filter(source == \"test\") %>% \n  select(-source, -response)\n\n\nfeatures <- train_df %>%\n  select(-id, -response, -policy_sales_channel) %>%\n  names()\n\ntrain_df <- train_df %>% \n  distinct(pick(all_of(features)), .keep_all = TRUE)\n\nnom_features <- train_df %>%\n  select(all_of(features)) %>%\n  select(where(is.character), where(is.factor)) %>%\n  names() \n\nlogical_features <- train_df %>%\n  select(all_of(features)) %>%\n  select(where(is.logical)) %>%\n  names() \n\nnum_features <- train_df %>%\n  select(all_of(features)) %>%\n  select(where(is.numeric)) %>%\n  names()\n\nbundle_split <- initial_split(train_df, prop = 0.9, strata = response)\nbundle_train <- training(bundle_split)\nbundle_test <- testing(bundle_split)\n\n\n```\n\nNominal features:\n\n`r nom_features`\n\nNumeric features: \n\n`r num_features`\n\nSize of the combined train and competition datasets:\n\n`r nrow(all_df)`\n\nSize of the split made available to machine learning\n\n`r nrow(bundle_train)`\n\n  \n           \n                \n# Machine Learning {.tabset .tabset-fade .tabset-pills}\n\n\n## Recipe\n\n```{r}\n#| label: recipe\n                   \nrec <- recipe(\n    \n    formula(paste0(\"response ~ \", \n               str_c(features,  collapse = \" + \"))),\n    data = bundle_train\n  ) %>% \n  step_novel(all_nominal_predictors())          \n                   \n                   \nfolds <- vfold_cv(bundle_train, \n                  v = 5,\n                  repeats = 1,\n                  strata = response)    \n                   \nctrl <- finetune::control_sim_anneal(     \n     verbose = FALSE,\n     verbose_iter = TRUE,\n     parallel_over = \"everything\",\n     event_level = \"second\",\n     save_pred = FALSE,\n     save_workflow = FALSE)                   \n                                     \n```\n\n\n\n## Lightgbm\n\n```{r}\n#| label: lgbm\n\n\nboost_tree_lgbm_spec <- \n  boost_tree(\n    trees = 1000L,\n   tree_depth = tune(),\n   learn_rate =  tune(),\n   min_n = tune(),\n   loss_reduction = 0\n  ) %>% \n  set_engine(engine = \"lightgbm\",\n             is_unbalance = TRUE,\n             num_leaves = tune(),\n             num_threads = cores\n             ) %>%\n  set_mode(mode = \"classification\") \n                   \nwf <- workflow(rec,\n               boost_tree_lgbm_spec) \n\nparam <- wf %>%\n   extract_parameter_set_dials() %>%\n   recipes::update(\n      min_n = min_n(),\n      tree_depth = tree_depth(range = c(5,25)),\n      learn_rate = learn_rate(range = c(-1,-2)),\n      num_leaves = num_leaves(range = c(70,250))\n   ) %>%\n   dials::finalize(raw_df)                 \n\nburnin <- tune_grid(\n  wf,\n  grid = 4,\n  resamples = folds,\n  control = ctrl,\n  metrics = metric_set(roc_auc, accuracy),\n  param_info = param)\n\nlgbm_rs <- finetune::tune_sim_anneal(\n  wf,\n  resamples = folds,\n  iter = 5,\n  initial = burnin,\n  control = ctrl,\n  metrics =  metric_set(roc_auc, accuracy),\n  param_info = param) \n\nshow_best(lgbm_rs, metric = \"roc_auc\")  \n\nautoplot(lgbm_rs)\n\n\n```\n                   \n# Submission\n                   \n```{r}\n#| label: submission\n#| warning: false\n#| message: false\n\nhighest_roc_auc <-   select_best(lgbm_rs, metric = \"roc_auc\")                 \n                   \nfinal_lgbm <- wf %>%\n    finalize_workflow(highest_roc_auc) \n\nlast_fit(\n  final_lgbm,\n  bundle_split\n) %>%\n  collect_metrics()\n\nclassification_fit <- final_lgbm %>%\n                        fit(bundle_train) \n\n# classification_fit %>%\n#  pull_workflow_fit() %>%\n#  vip::vi() %>%\n#  mutate(\n #   Importance = abs(Importance),\n #   Variable = fct_reorder(Variable, Importance)\n#  ) %>%\n#  ggplot(aes(x = Importance, y = Variable)) +\n # geom_col() +\n#  scale_x_continuous(expand = c(0, 0)) +\n # labs(y = NULL)                         \n                   \nsubmit_df <-  augment(classification_fit, competition_df, type = \"prob\") %>%\n       select(id, Response = .pred_1)\n\nhead(submit_df)  %>% \n     knitr::kable()      \n\nsubmit_df  %>% \n  write_csv(\"submission.csv\")\n```     ","metadata":{"_uuid":"83d1a4d2-c6c0-45ce-972c-fac5ae2e1b1e","_cell_guid":"64dc6217-85bd-4bfb-88d1-115a526ae9a6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}