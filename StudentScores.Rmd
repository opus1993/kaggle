{"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":119082,"databundleVersionId":14993753,"sourceType":"competition"}],"dockerImageVersionId":30749,"isInternetEnabled":true,"language":"rmarkdown","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"---\ntitle: \"Student Test Scores\"\ndate: '`r Sys.Date()`'\noutput:\n  html_document:\n    number_sections: true\n    fig_caption: true\n    toc: true\n    fig_width: 7\n    fig_height: 4.5\n    theme: cosmo\n    highlight: tango\n    code_folding: hide\n---\n\n![](https://ed.stanford.edu/sites/default/files/styles/free_crop_original/public/news_images/albertogp123_0.jpg)\n\n# Introduction  {.tabset .tabset-fade .tabset-pills}\n\nThe goal of this competition is to predict student test scores.\n\nMy notebook serves as a demonstration of some of the possible techniques available to arrive at a solution.  I intend to add to this as I have time available. Your questions and comments are welcome.\n\nLets dive right in.\n\nThe Kaggle kernels have many of the common r packages built in.  \n\n## Load libraries\n\n```{r }\n#| label: setup\n#| warning: false\n#| message: false\n\nif (dir.exists(\"/kaggle\")){\n  path <- \"/kaggle/input/playground-series-s6e1/\"\n    \n# options(repos = c(CRAN = \"https://packagemanager.posit.co/cran/2021-03-22\"))\n\ninstall.packages(\"pak\")\npak::pak(\"bonsai\")\npak::pak(\"ggplot2\")\npak::pak(\"modeldb\")\n    \nremotes::install_github(\"luisdva/hexsession\", quiet = TRUE)    \n\ncores <- future::availableCores()\n\n} else {\n  path <- stringr::str_c(here::here(\"data\"),\"/\")\n  orig_path <- stringr::str_c(here::here(\"data\"),\"/\")\n\n  cores <- future::availableCores(omit = 2)\n  \n}\n \nsuppressPackageStartupMessages({\nlibrary(tidyverse, quietly = TRUE) # metapackage of all tidyverse packages\nlibrary(tidymodels, quietly = TRUE) # metapackage see https://www.tidymodels.org/\n\nlibrary(correlationfunnel)\n\nlibrary(bonsai)  # Tidymodels access to lightgbm\nlibrary(stacks)  # Tidymodels ensembling\n    \nlibrary(DALEXtra) # Tidymodels Explainability         \n\n# library(mirai)\n# daemons(cores)\n    \n})\n\nconflicted::conflict_prefer(\"select\", \"dplyr\")\nconflicted::conflict_prefer(\"where\", \"dplyr\")\n\n\ntidymodels_prefer()\n\noptions(tidymodels.dark = TRUE)\n\ntheme_set(theme_minimal())\n\nhexsession::make_tile(packages = c(\"lightgbm\",\"bonsai\",\"DALEXtra\", \"DALEX\",  \"correlationfunnel\",\"yardstick\",\"workflows\",\n                                   \"tune\",\"rsample\",\"recipes\",\"parsnip\",\"dials\",\"broom\",\"tidymodels\",\"lubridate\",\n                                   \"forcats\",\"stringr\",\"dplyr\",\"purrr\",\"readr\",\"tidyr\",\"tibble\",\"ggplot2\",\"tidyverse\"),\n                     highlight_mode = TRUE\n                     )\n\n\n```\n\n\n\n## Load Data\n\n```{r }\n#| label: load data\n#| warning: false\n#| message: false\n\npreprocessor <- function(dataframe) {\n\ndataframe <- dataframe |>\n    janitor::clean_names() |> \n    \n    mutate(across(c(where(is.character)), \\(x) as.factor(x)))  \n\nreturn(dataframe)\n}\n\nraw_df <- read_csv(str_c(path, \"train.csv\"),\n                   show_col_types = FALSE) \n\ntst_df <- read_csv(str_c(path, \"test.csv\"),\n                   show_col_types = FALSE)  \n\nall_df <-\n    bind_rows(raw_df %>% mutate(source = \"train\"),\n              tst_df %>% mutate(source = \"test\")) |>\n          preprocessor() \n\ncluster_fit <- all_df |> \n  select(-id, -exam_score, -source) |> \n\n  modeldb::add_dummy_variables(gender, auto_values = TRUE) |> \n  modeldb::add_dummy_variables(course, auto_values = TRUE) |> \n  modeldb::add_dummy_variables(internet_access, auto_values = TRUE) |> \n  modeldb::add_dummy_variables(sleep_quality, auto_values = TRUE) |> \n  modeldb::add_dummy_variables(study_method, auto_values = TRUE) |> \n  modeldb::add_dummy_variables(facility_rating, auto_values = TRUE) |> \n  modeldb::add_dummy_variables(exam_difficulty, auto_values = TRUE) |> \n  \n  mutate(across(where(is.numeric), scale)) |> \n  kmeans(centers = 30)\n\nall_df <- all_df |> \n  bind_cols(tibble(cluster = factor(fitted(cluster_fit, method = \"classes\"))))\n\ntrain_df <- all_df %>% \n  filter(source == \"train\") %>% \n  select(-source) \n\ncompetition_df <- all_df %>% \n  filter(source == \"test\") %>% \n  select(-source, -exam_score)\n\n\n```\n\n\n\n\n## Features\n\nWe will de-duplicate the training set and use the first exam_score data point.\n\n```{r}\n#| label: Features\n#| warning: false\n#| message: false\n\n\n\nfeatures <- train_df %>%\n  dplyr::select(-id, -exam_score) |> \n  names()\n\ntrain_df <- train_df %>% \n  dplyr::group_by(pick({{features}})) |> \n  dplyr::summarise(id = min(id),\n                   exam_score = first(exam_score),\n                   .groups = \"drop\")\n\nnom_features <- train_df |> \n  dplyr::select(dplyr::all_of(features)) |> \n  dplyr::select(dplyr::where(is.factor)) |> \n  names() \n\nlogical_features <- train_df |> \n  dplyr::select(dplyr::all_of(features)) |> \n  dplyr::select(dplyr::where(is.logical)) |> \n  names() \n\nnum_features <- train_df |> \n  dplyr::select(dplyr::all_of(features)) |> \n  dplyr::select(dplyr::where(is.numeric)) |> \n  names()\n```\n\nNominal features:\n\n`r nom_features`\n\nNumeric features: \n\n`r num_features`\n\nLogical features: \n\n`r logical_features`\n\n\nSize of the combined train and competition datasets:\n\n`r nrow(all_df)`\n\nSize of training set after de-duplication\n\n`r nrow(train_df)`\n\n\n\n# EDA {.tabset .tabset-fade .tabset-pills}\n\n## Numeric features\n\n\n```{r}\n#| label: numeric\n#| warning: false\n#| message: false\n\ntrain_df %>% \n  dplyr::select(all_of(num_features), exam_score ) %>% \n  pivot_longer(-exam_score,\n    names_to = \"metric\",\n    values_to = \"value\"\n  ) %>%\n  ggplot(aes(value, fill = ggplot2::cut_number(exam_score, 5))) +\n  geom_density(position = \"stack\") +\n  scale_fill_brewer(type = \"seq\", palette = \"YlOrRd\") +\n  facet_wrap(vars(metric), scales = \"free\", ncol = 3) +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        \n    strip.text = element_text(face = \"bold\", hjust = 0, size = rel(0.5), margin = margin_part(b = 5, l = -10)),\n    strip.clip = \"off\",\n    panel.spacing = unit(2, \"lines\"),\n    \n        legend.position = \"top\") +\n  labs(color = NULL, fill = \"exam_score\",\n       title = \"Numeric Feature Univariate Distributions\",\n       caption = \"Data: Kaggle | Visual: Jim Gruman\")\n\ntrain_df %>% \n  dplyr::select(all_of(num_features), exam_score ) %>% \n  pivot_longer(-exam_score,\n    names_to = \"metric\",\n    values_to = \"value\"\n  ) %>%\n  ggplot(aes(value, exam_score)) +\n  geom_bin_2d() +\n  geom_smooth(se = FALSE) +\n  scale_fill_distiller(type = \"seq\", palette = \"YlOrRd\") +\n  facet_wrap(vars(metric), scales = \"free\", ncol = 2) +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        \n    strip.text = element_text(face = \"bold\", hjust = 0, size = rel(0.5), margin = margin_part(b = 5, l = -10)),\n    strip.clip = \"off\",\n    panel.spacing = unit(2, \"lines\"),\n    \n        legend.position = \"right\") +\n  labs(title = \"Numeric Feature Univariate Distributions\",\n       caption = \"Data: Kaggle | Visual: Jim Gruman\")\n\n```\n\n\n## Nominal and Logical features\n\nExplore the distribution of outcome class by factor level.\n\n\n```{r}\n#| label: nominal\n#| warning: false\n#| message: false\n#| fig-height: 12\n\nif(length(nom_features) >0){\n\ntrain_df %>% \n  select(all_of(nom_features), all_of(logical_features), exam_score) %>% \n  mutate(across(nom_features, fct_lump_n, n = 5, other_level = 'other', ties.method = \"first\"),\n         across(logical_features, \\(x) factor(x))) %>%\n  pivot_longer(-exam_score,\n    names_to = \"metric\",\n    values_to = \"value\"\n  ) %>%\n    \n  filter(!is.na(exam_score)) %>% \n    \n  summarise(n = n(),\n            .by = c(exam_score, metric, value)) %>%\n      \n  mutate(value = tidytext::reorder_within(value, n, metric)) %>%\n    \n  ggplot(aes(x = n, y = value, fill = ggplot2::cut_number(exam_score, 5))) +\n  geom_col() +\n  tidytext::scale_y_reordered() +\n  scale_x_continuous(n.breaks = 3, guide = guide_axis(n.dodge = 2))  +\n  scale_fill_brewer(type = \"seq\", palette = \"YlOrRd\") +\n  facet_wrap(vars(metric), scales = \"free\", ncol = 2) +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n  #  strip.text = element_text(margin = margin_part(b = -20, l = 8)),\n  #  strip.clip = \"off\",\n  #  panel.spacing = unit(2, \"lines\"),\n       legend.position = \"bottom\") +\n  labs(title = \"Nominal Feature Counts\",\n       fill = NULL, y = NULL,\n       caption = \"Data: Kaggle | Visual: Jim Gruman\")\n\n}\n\n```\n\n## Counts of Missingness\n\n                  \n```{r}\n#| label: counts of missingness\n\ntrain_df %>% \n  summarize(across(all_of(features), function(x) sum(is.na(x)))) %>% \n  pivot_longer(everything(),\n              names_to = \"feature\",\n              values_to = \"Count of Missing\") %>% \n                   knitr::kable()\n\ncompetition_df %>% \n  summarize(across(all_of(features), function(x) sum(is.na(x)))) %>% \n  pivot_longer(everything(),\n              names_to = \"feature\",\n              values_to = \"Count of Missing\") %>% \n                   knitr::kable()\n\n```\n\n## Counts of Distinct\n                   \n               \n```{r}\n#| label: counts of distinct\n               \ntrain_df %>%\n  summarize(across(all_of(features), n_distinct)) %>%\n  pivot_longer(everything(), names_to = \"feature\", values_to = \"Count of distinct train\") |>\n  left_join(\n    competition_df %>%\n      summarize(across(all_of(features), n_distinct)) %>%\n      pivot_longer(everything(), names_to = \"feature\", values_to = \"Count of distinct test\"),\n    by = join_by(feature)\n  ) %>% \n                   knitr::kable()\n               \n```\n\n## Duplicated\n\nIs this competition transaction already in the training data with a correct label?\n\n\n```{r}\n#| label: duplicates\n#| warning: false\n#| message: false\n\nbind_rows(train_df %>% mutate(source = \"train\"),\n              competition_df %>% mutate(source = \"test\")) |> \n    group_by_at(features) %>%\n    mutate(num_dups = n(),\n           dup_id = row_number()) %>% \n    ungroup() %>% \n    group_by(source) %>%\n    mutate(is_duplicated = dup_id > 1) %>% \n    count(is_duplicated) %>% \n                   knitr::kable()\n\n\n\n```\n\n\n## Pairwise Correlations\n                   \n`ggcorrplot` provides a quick look at numeric features where the correlation may be significant. \n\n```{r}\n#| label: pairwise correlations\n#| fig-width: 9\n\ntrainp.mat <- train_df %>% \n  mutate(exam_score = as.numeric(exam_score)) |> \n  select(all_of(num_features), exam_score) %>% \n  ggcorrplot::cor_pmat() \n                   \ntrain_df %>% \n  mutate(exam_score = as.numeric(exam_score)) |> \n  select(all_of(num_features), exam_score) %>%                    \n  cor() %>% \n  ggcorrplot::ggcorrplot(hc.order = TRUE, \n                         lab = TRUE,\n                         p.mat = trainp.mat,\n    type = \"lower\", insig = \"blank\") +\n  labs(title = \"Pairwise Correlations Training Set\")\n                   \ncompetitionp.mat <- competition_df %>% \n  select(all_of(num_features)) %>% \n  ggcorrplot::cor_pmat() \n                   \ncompetition_df %>% \n  select(all_of(num_features)) %>%                   \n  cor()   %>% \n  ggcorrplot::ggcorrplot(hc.order = TRUE, lab = TRUE,\n                         p.mat = competitionp.mat,\n    type = \"lower\", insig = \"blank\") +\n   labs(title = \"Pairwise Correlations Competition Set\")\n\n```                    \n\n## Correlation Funnel\n\n\n```{r}\n#| label: correlation funnel \n#| warning: false\n#| message: false\n\n\ny_df <- train_df |>\n  transmute(exam_score = as.numeric(exam_score)) \n\ntrain_df %>%\n  select(all_of(num_features)) %>%\n  correlationfunnel::binarize(one_hot = TRUE, n_bins = 3) %>%\n  bind_cols(y_df) |>\n  correlate(target = exam_score) %>%\n  plot_correlation_funnel()\n\n``` \n                   \n                   \n## Target\n\nTraining scores range from 19.5 to 100, with many of them at either extreme.\n\n```{r}\n#| label: outcome \n#| warning: false\n#| message: false\n#| fig.width: 6\n\n\ntrain_df |> count(exam_score)  |> arrange(exam_score)   \n\ntrain_df |> count(exam_score) |> arrange(desc(exam_score))     \n\ntrain_df %>% \n  ggplot(aes(exam_score)) +\n  geom_histogram(bins = 100) +\n  labs(title = \"Exam Score\",\n       caption = \"Data: Kaggle.com | Visual: Jim Gruman\")\n\n``` \n                \n# Machine Learning {.tabset .tabset-fade .tabset-pills}\n\n\n## Recipe\n\n```{r}\n#| label: recipe\n#| warning: false\n#| message: false\n#| fig.width: 6\n                   \nlgbm_rec <- recipe(formula(paste0(\"exam_score ~ \", str_c(features, collapse = \" + \"))), data = train_df) \n                                     \nfolds <- vfold_cv(train_df,\n                  v = 15,\n                  repeats = 1,\n                  strata = exam_score)\n```\n\n\n## Machine Learning \n\n\n```{r}\n#| label: ml \n#| warning: false\n#| message: false\n                   \nboost_tree_lgbm_spec <- \n  boost_tree(\n    trees = 1800,\n    tree_depth = tune(),\n    learn_rate =  tune(),\n    min_n = tune(),\n    stop_iter = 60\n      \n  ) %>% \n  set_engine(engine = \"lightgbm\" ,\n             num_threads = cores,\n             num_leaves = tune()) %>%  \n  set_mode(mode = \"regression\")             \n\ndep_models <-\n   workflow_set(\n      preproc = list(base = lgbm_rec),\n      models = list(lgbm = boost_tree_lgbm_spec),\n      cross = FALSE\n   ) %>%\n  option_add_parameters() |>\n  option_add(\n    control = finetune::control_sim_anneal( save_pred = TRUE, save_workflow = TRUE, verbose = TRUE, verbose_iter = TRUE),\n    metrics = metric_set(rmse)\n  )\n\nlgbm_params <- dep_models |>\n extract_workflow(\"base_lgbm\") |>\n extract_parameter_set_dials() |>\n update(\n         tree_depth = tree_depth(range = c(10, 25)),\n         min_n = min_n(range = c(1, 15)),\n         num_leaves = num_leaves(range = c(110,170)),\n         learn_rate = learn_rate(range = c(-1.7,-1.3))\n ) \n\nall_models <- dep_models |>\n option_add(\n   param_info = lgbm_params,\n   id = \"base_lgbm\"\n ) |>\n  workflow_map(\"tune_sim_anneal\", \n               resamples = folds, \n               iter = 20,\n               metrics = metric_set(rmse), verbose = TRUE)             \n\nautoplot(all_models) +\n  geom_text(aes(y = mean -0.002, label = wflow_id), angle = 90, hjust = 1)+\n  scale_y_continuous(limits = c(0,NA), expand = c(0, 0)) |>\n  theme(legend.position = \"none\")\n\nrank_results(all_models, rank_metric = \"rmse\", select_best = TRUE) %>%\n   select(rank, mean, model, wflow_id, .config) |> \n   arrange(mean)\n \nall_models %>%\n  dplyr::filter(grepl(\"lgbm\", wflow_id)) %>%\n  mutate(metrics = map(result, collect_metrics)) %>%\n  dplyr::select(wflow_id, metrics) %>%\n  tidyr::unnest(cols = metrics) |>\n  arrange(mean)\n\nall_models |>\n  workflowsets::extract_workflow_set_result(\"base_lgbm\") |>\n  autoplot() +\n  labs(title = \"Lightgbm Hyperparameter Search\")\n\n\ndep_stack <- stacks() %>%\n  add_candidates(all_models) %>%\n  blend_predictions(  metric =  metric_set(rmse),\n      penalty = c(10^seq(-4.7, -3.3, 0.1)),\n      non_negative = TRUE,\n      control = tune::control_grid(allow_par = TRUE))\n\nautoplot(dep_stack)\n\nautoplot(dep_stack, type = \"members\")        \n                   \nautoplot(dep_stack, \"weights\")\n                   \nregression_fit <- dep_stack %>% \n    fit_members()                   \n\n```\n\n\n\n# Performance {.tabset .tabset-fade .tabset-pills}\n\n```{r}\n#| label: explainer\n#| warning: false\n#| message: false\n#| fig.height: 12\n                   \n                   \nexplainer <- \n  explain_tidymodels(\n    regression_fit, \n    data = train_df %>% dplyr::select(all_of(features)), \n    y = as.numeric(train_df$exam_score),\n    label = \"Ensemble\",\n    verbose = FALSE\n  )  %>% \n  model_parts()\n\nggplot_imp <- function(...) {\n  obj <- list(...)\n  metric_name <- attr(obj[[1]], \"loss_name\")\n  metric_lab <- paste(metric_name, \n                      \"after permutations\\n(higher indicates more important)\")\n  \n  full_vip <- bind_rows(obj) %>%\n    filter(variable != \"_baseline_\")\n  \n  perm_vals <- full_vip %>% \n    filter(variable == \"_full_model_\") %>% \n    group_by(label) %>% \n    summarise(dropout_loss = mean(dropout_loss))\n  \n  p <- full_vip %>%\n    filter(variable != \"_full_model_\") %>% \n    mutate(variable = fct_reorder(variable, -dropout_loss)) %>%\n    ggplot(aes(dropout_loss, variable)) \n  \n  if(length(obj) > 1) {\n    p <- p + \n      facet_wrap(vars(label)) +\n      geom_vline(data = perm_vals, aes(xintercept = dropout_loss, color = label),\n                 linewidth = 1.4, lty = 2, alpha = 0.7) +\n      geom_boxplot(aes(color = label, fill = label), alpha = 0.2)\n  } else {\n    p <- p + \n      geom_vline(data = perm_vals, aes(xintercept = dropout_loss),\n                 linewidth = 1.4, lty = 2, alpha = 0.7) +\n      geom_boxplot(fill = \"#91CBD765\", alpha = 0.4)\n    \n  }\n  p +\n    theme(legend.position = \"none\") +\n    labs(x = metric_lab, \n         y = NULL,  fill = NULL,  color = NULL)\n}\n                   \nggplot_imp(explainer)      \n                       \n\n```                      \n\n\n                   \n# Submission\n                   \n\n```{r}\n#| label: submission\n#| warning: false\n#| message: false\n#| fig.height: 6\n#| fig.width: 6   \n                 \npredict(regression_fit, train_df) %>% \n  bind_cols(train_df) |> \n  ggplot(aes(exam_score, .pred)) +\n  geom_bin_2d() +\n  geom_abline(color = \"green\") +\n  scale_fill_distiller(type = \"seq\", palette = \"YlOrRd\")\n                   \nsubmit_df <- predict(regression_fit, competition_df) |>\n  bind_cols(competition_df) |>\n  transmute(\n   id,\n  exam_score = .pred)\n\nhead(submit_df)  %>% \n     knitr::kable()      \n\nsubmit_df  %>% \n  write_csv(\"submission.csv\")\n```   ","metadata":{"_uuid":"2d13c35e-e6bd-4c43-b541-d6c15eae14a3","_cell_guid":"cbddae98-7461-442f-bf3d-94d5fdaa27cb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}