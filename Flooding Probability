---
title: "Regression with a Flood Prediction Dataset"
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: cosmo
    highlight: tango
    code_folding: hide
---
  
# Introduction  {.tabset .tabset-fade .tabset-pills}

The goal of this competition is to predict the predict the probability of a region flooding.

My notebook serves as a demonstration of some of the possible techniques available to arrive at a solution.  I intend to add to this as I have time available. Your questions and comments are welcome.

If you fork this on kaggle, be sure to choose the kernel Environment setting for "Always use latest environment"

Lets dive right in.

The Kaggle kernels have many of the common r packages built in.  

## Load libraries

In addition to `tidymodels` we will load the `bonsai` interface to lightgbm.

```{r }
#| label: setup
#| warning: false
#| message: false

options(repos = c(CRAN = "https://packagemanager.posit.co/cran/__linux__/jammy/latest"))

#install.packages("tidymodels", quiet = TRUE, verbose = FALSE, dependencies = TRUE)
#install.packages("agua", quiet = TRUE, verbose = FALSE, dependencies = TRUE)
 
suppressPackageStartupMessages({
library(tidyverse, quietly = TRUE) # metapackage of all tidyverse packages
library(tidymodels) # metapackage see https://www.tidymodels.org/
  
library(agua)
    
})

tidymodels_prefer()

options(tidymodels.dark = TRUE)

theme_set(cowplot::theme_minimal_grid())

```


## Interchangeability

I prefer to be able to run the same code locally and on a Kaggle kernel.

```{r}
#| label: interchangeability
#| warning: false
#| message: false

if (dir.exists("/kaggle")){
  path <- "/kaggle/input/playground-series-s4e5/"
} else {
  path <- str_c(here::here("data"),"/")
}

path

```

## Load Data

```{r }
#| label: load data
#| warning: false
#| message: false
future::plan("multisession", workers = future::availableCores())

preprocessor <- function(dataframe) {


  dataframe %>%
    janitor::clean_names() %>%
    mutate(across(c(where(is.character)), ~ as.factor(.x)), ) %>%
    mutate(flood_median = furrr::future_pmap_dbl(select(., monsoon_intensity:political_factors), .f = lift_vd(median))) %>%
    mutate(flood_max = furrr::future_pmap_dbl(select(., monsoon_intensity:political_factors), .f = lift_vd(max))) %>%
    mutate(flood_min = furrr::future_pmap_dbl(select(., monsoon_intensity:political_factors), .f = lift_vd(min))) %>%
    mutate(flood_total = furrr::future_pmap_dbl(select(., monsoon_intensity:political_factors), .f = lift_vd(sum))) %>%
    mutate(flood_sd = furrr::future_pmap_dbl(select(., monsoon_intensity:political_factors), .f = lift_vd(sd)))  %>%
    mutate(flood_range = flood_max - flood_min) %>%
    mutate(across(monsoon_intensity:political_factors, ~ as.factor(.x)))

}

raw_df <- read_csv(str_c(path, "train.csv"),
                   show_col_types = FALSE) %>%

  preprocessor() 

features <- raw_df %>%
  select(-id, -flood_probability) %>%
  names()

raw_df <- raw_df %>% 
  distinct(pick(all_of(features)), .keep_all = TRUE)

nom_features <- raw_df %>%
  select(all_of(features)) %>%
  select(where(is.character), where(is.factor)) %>%
  names() 

logical_features <- raw_df %>%
  select(all_of(features)) %>%
  select(where(is.logical)) %>%
  names() 

num_features <- raw_df %>%
  select(all_of(features)) %>%
  select(where(is.numeric)) %>%
  names()

competition_df <- read_csv(str_c(path, "test.csv"),
                   show_col_types = FALSE)  %>% 
  preprocessor() 

all_df <-
    bind_rows(raw_df %>% mutate(source = "train"),
            competition_df %>% mutate(source = "test"))

future::plan("sequential")  


```

Nominal features:

`r nom_features`

Numeric features: 

`r num_features`


# EDA {.tabset .tabset-fade .tabset-pills}

## Numeric features

Consider where features require univariate transformation, or clipping outliers.
```{r}
#| label: numeric
#| warning: false
#| message: false
#| fig.height: 12
#| fig.width: 12

raw_df %>% 
  select(all_of(num_features), flood_probability) %>% 
  pivot_longer(-flood_probability,
    names_to = "metric",
    values_to = "value"
  ) %>%
  ggplot(aes(value, fill = ggplot2::cut_number(flood_probability,3))) +
  geom_histogram(alpha = 0.6, bins = 50) +
   facet_wrap(vars(metric), scales = "free", ncol = 3) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  labs(color = NULL, fill = "Flood Probability",
       title = "Numeric Feature Univariate Distributions",
       caption = "Data: Kaggle.com | Visual: Jim Gruman")

raw_df %>% 
  select(all_of(num_features), flood_probability) %>% 
  pivot_longer(-flood_probability,
    names_to = "metric",
    values_to = "value"
  ) %>%
  ggplot(aes(value, flood_probability)) +
  geom_jitter(alpha = 0.01, shape = 21) +
  geom_smooth(method = "lm", color = "darkgreen") +
   facet_wrap(vars(metric), scales = "free", ncol = 3) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  labs(color = NULL, 
       title = "Numeric Feature versus Flood Probability",
       caption = "Data: Kaggle.com | Visual: Jim Gruman")
```


## Nominal features

```{r}
#| label: nominal
#| warning: false
#| message: false
#| fig.height: 12
#| fig.width: 12

raw_df %>% 
  select(all_of(nom_features), flood_probability) %>% 
  pivot_longer(-flood_probability,
    names_to = "metric",
    values_to = "value"
  ) %>%
  ggplot(aes(value)) +
  geom_bar() +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
   facet_wrap(vars(metric), scales = "free", ncol = 4) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  labs(title = "Nominal Feature Counts",
       caption = "Data: Kaggle.com | Visual: Jim Gruman")

raw_df %>% 
  select(all_of(nom_features), flood_probability) %>% 
  pivot_longer(-flood_probability,
    names_to = "metric",
    values_to = "value"
  ) %>%
  ggplot(aes(value, flood_probability)) +
  geom_boxplot() +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
   facet_wrap(vars(metric), scales = "free", ncol = 4) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  labs(title = "Nominal Feature Versus Outcome",
       caption = "Data: Kaggle.com | Visual: Jim Gruman")

```

## Counts of Missingness
                  
```{r}
#| label: counts of missingness

raw_df %>% 
  summarize(across(all_of(features), function(x) sum(is.na(x)))) %>% 
  pivot_longer(everything(),
              names_to = "feature",
              values_to = "Count of Missing") %>% 
                   knitr::kable()
```

## Counts of Distinct
               
```{r}
#| label: counts of distinct
               
raw_df %>% 
  summarize(
    across(all_of(features), n_distinct)
  ) %>%
  pivot_longer(everything(),
               names_to = "feature",
               values_to = "Count of distinct") %>% 
                   knitr::kable()
               
```

## Duplicated

Is this competition transaction already in the training data with a correct label?

```{r}
#| label: duplicates
#| warning: false
#| message: false
all_df %>%
    select(all_of(features), source) %>% 
    group_by_at(features) %>%
    mutate(num_dups = n(),
           dup_id = row_number()) %>%
    ungroup() %>%
    group_by(source) %>%
    mutate(is_duplicated = dup_id > 1) %>%
    count(is_duplicated) %>% 
                   knitr::kable()
               

```
                   
## Pairwise Correlations
                   
`ggcorrplot` provides a quick look at numeric features where the correlation may be significant. 
                         

```{r}
#| label: pairwise correlations
# Leave blank on no significant coefficient
#| fig.height: 12
#| fig.width: 12
                   
corr <- raw_df %>%
  select(all_of(num_features), flood_probability) %>%
  cor()

p.mat <-raw_df %>%
  select(all_of(num_features), flood_probability) %>%
  ggcorrplot::cor_pmat() 

ggcorrplot::ggcorrplot(
    corr,
    hc.order = TRUE,
    lab_size = 1.5,
    tl.cex = 4,
    pch.cex = 8,
    digits = 2,
    lab = TRUE,
    type = "lower",
    show.diag = TRUE,
    insig = "blank",
    p.mat = p.mat
  ) +
  labs(title = "Pairwise Correlations Training Set")

ggcorrplot::ggcorrplot(
   competition_df %>%
    select(all_of(num_features)) %>%
    cor(),
    hc.order = TRUE,
    lab_size = 1.5,
    tl.cex = 4, 
    pch.cex = 8,
    digits = 2,
    lab = TRUE,
    type = "lower",
   show.diag = TRUE,
    insig = "blank",
    p.mat = competition_df %>%
  select(all_of(num_features)) %>%
  ggcorrplot::cor_pmat() 
  ) +
  labs(title = "Pairwise Correlations Competition Set")

```      


## Target

```{r}
#| label: outcome 
#| warning: false
#| message: false
#| fig.width: 12

raw_df %>% 
 ggplot(aes(flood_probability)) +
  geom_histogram(bins = 100) +
  labs(title = "Outcome: Flood Probability",
       caption = "Data: Kaggle.com | Visual: Jim Gruman")

```
                              
           
                
# Machine Learning {.tabset .tabset-fade .tabset-pills}

## Recipe
                

```{r}
#| label: recipe
#| fig.height: 30
#| fig.width: 30

rec <- recipe(
    
    formula(paste0("flood_probability ~ ", 
               str_c(features,  collapse = " + "))),
    data = raw_df 
  ) 
                                     
```

## H2O AutoML Engine

```{r}
#| label: h2o engine

h2o_spec <- auto_ml() %>%
  set_engine("h2o", 
             max_runtime_secs = 1*60*60, 
             seed = 1,
             nfolds = 5,
             validation = 0.1,
             stopping_metric = "deviance",
             stopping_rounds = 25
             ) %>%
  set_mode("regression")
                   
available_cores <- parallelly::availableCores()
available_cores

# h2o_start()
h2o::h2o.init(nthreads = available_cores)                   

h2o_spec

```

## H2O Fit                                                                     

```{r}
#| label: agua fit 
#| warning: false
#| message: false
#| fig.height: 6
#| fig.width: 12
tictoc::tic()

auto_fit <- fit(workflow(rec, h2o_spec) , data = raw_df)             
                   
auto_fit %>%
  extract_fit_parsnip() %>%
  member_weights() %>%
  unnest(importance) %>%
  filter(type == "scaled_importance") %>%
  ggplot() +
  geom_boxplot(aes(value, algorithm)) +
  scale_x_sqrt() +
  labs(y = NULL, x = "scaled importance", title = "Member importance in stacked ensembles")


predict(auto_fit, raw_df) %>% 
  bind_cols(raw_df) %>% 
  rsq(flood_probability, .pred)

predict(auto_fit, raw_df) %>%
  bind_cols(raw_df) %>% 
  ggplot(aes(flood_probability, flood_probability - .pred)) +
  geom_jitter(alpha = 0.1, shape = 21) +
  labs(caption = "Residuals")
                   
                   

tictoc::toc()                    
```
                   
## Submission
                 
             
                   
```{r}
#| label: submission
#| warning: false
#| message: false
                   
submit_df <- predict(auto_fit, competition_df) %>%
  bind_cols(competition_df) %>%
  mutate(.pred = case_when(
      .pred < 0 ~ 0,
      .pred > 1 ~ 1,
      TRUE ~ .pred
  )) %>%
  transmute(id, FloodProbability = .pred)

head(submit_df)  %>% 
     knitr::kable()      
                   
 submit_df %>% ggplot(aes(FloodProbability)) + geom_histogram(bins = 500)                   
                   
submit_df  %>% 
  write_csv("submission.csv")
```                   