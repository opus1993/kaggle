---
title: "Higgs Boson"
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: cosmo
    highlight: tango
    code_folding: hide
---
  
# Introduction  {.tabset .tabset-fade .tabset-pills}

The goal of this competition is to classify events into two classes: events that produce the exotic Higgs Boson particle, and those that do not.

My notebook serves as a demonstration of some of the possible techniques available to arrive at a solution.  I intend to add to this as I have time available. Your questions and comments are welcome.

Lets dive right in.

The Kaggle kernels have many of the common r packages built in.  

## Load libraries

In addition to `tidymodels` we will load the `bonsai` interface to lightgbm.

```{r }
#| label: setup
#| warning: false
#| message: false

if (dir.exists("/kaggle")){
  path <- "/kaggle/input/higgs-boson-detection-2025/"

options(repos = c(CRAN = "https://packagemanager.posit.co/cran/2021-03-22"))

cores <- future::availableCores()

} else {
  path <- stringr::str_c(here::here("data"),"/")
  orig_path <- stringr::str_c(here::here("data"),"/")

  cores <- future::availableCores(omit = 7)
}
 
suppressPackageStartupMessages({
library(tidyverse, quietly = TRUE) # metapackage of all tidyverse packages
library(tidymodels) # metapackage see https://www.tidymodels.org/
  
library(discrim)  
library(baguette)  
  
library(bonsai)  
library(stacks)
 # interface to lightgbm

})

tidymodels_prefer()

options(tidymodels.dark = TRUE)

theme_set(ggdark::dark_theme_minimal())

```

## Load Data


```{r }
#| label: load data
#| warning: false
#| message: false

preprocessor <- function(dataframe) {

dataframe <- dataframe %>%
    janitor::clean_names() |>

    mutate(across(c(where(is.character)), ~ as.factor(.x))) 

return(dataframe)
}

raw_df <- read_csv(str_c(path, "train.csv"),
                   show_col_types = FALSE) |> 
          mutate(label = as.character(label)) |> 
          preprocessor() 

tst_df <- read_csv(str_c(path, "test.csv"),
                   show_col_types = FALSE)  |>  
  preprocessor() 

# because we already know the test set, let's remove the train set factor levels that do not correspond with anything on the test set
for (col in names(raw_df)) {
    if (is.factor(raw_df[[col]]) & col != "label") {
      # Get levels in train and test dataframes
      raw_levels <- levels(raw_df[[col]])
      tst_levels <- levels(tst_df[[col]])
      
      # Identify levels in train not in test
      new_levels <- setdiff(raw_levels, tst_levels)
      
      # Set these levels to NA in train dataframe
      raw_df[[col]] <- factor(raw_df[[col]], levels = c(tst_levels, new_levels))
      raw_df[[col]][raw_df[[col]] %in% new_levels] <- NA_character_
    }
  }

# the synthetic playground competitions seem to perform better when numerics are also included as factors
all_df <-
    bind_rows(raw_df %>% mutate(source = "train"),
              tst_df %>% mutate(source = "test")) 


train_df <- all_df %>% 
  filter(source == "train") %>% 
  select(-source) 

competition_df <- all_df %>% 
  filter(source == "test") %>% 
  select(-source, -label)

features <- train_df %>%
  select(-label) |> 
  names()

train_df <- train_df %>% 
  distinct(pick(all_of(features)), .keep_all = TRUE)

nom_features <- train_df %>%
  select(all_of(features)) %>%
  select(where(is.character), where(is.factor)) %>%
  names() 

logical_features <- train_df %>%
  select(all_of(features)) %>%
  select(where(is.logical)) %>%
  names() 

num_features <- train_df %>%
  select(all_of(features)) %>%
  select(where(is.numeric)) %>%
  names()


```

Nominal features:

`r nom_features`

Numeric features: 

`r num_features`

Logical features: 

`r logical_features`


Size of the combined train and competition datasets:

`r nrow(all_df)`

Size of the split made available to machine learning

`r nrow(train_df)`


# EDA {.tabset .tabset-fade .tabset-pills}

## Numeric features

Consider where features require univariate transformation, or clipping outliers.
```{r}
#| label: numeric
#| warning: false
#| message: false
#| fig.height: 16
#| fig.width: 6

train_df %>% 
  select(all_of(num_features), label ) %>% 
  pivot_longer(-label,
    names_to = "metric",
    values_to = "value"
  ) %>%
  ggplot(aes(value, fill = label)) +
  geom_histogram(show.legend = FALSE, bins = 200) +
   facet_wrap(vars(metric), scales = "free", ncol = 2) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.title.position = "plot") +
  labs(color = NULL, fill = "Loan Status",
       title = "Numeric Feature Univariate Distributions",
       caption = "Data: Kaggle.com | Visual: Jim Gruman")

```



## Counts of Missingness
                  
```{r}
#| label: counts of missingness

train_df %>% 
  summarize(across(all_of(features), function(x) sum(is.na(x)))) %>% 
  pivot_longer(everything(),
              names_to = "feature",
              values_to = "Count of Missing") %>% 
                   knitr::kable()
                  

```

## Counts of Distinct
                   
This dataset has quite a few unusual factor levels. And more important, there are factor levels in test that do not appear in train.
               
```{r}
#| label: counts of distinct
               
train_df %>%
  summarize(across(all_of(features), n_distinct)) %>%
  pivot_longer(everything(), names_to = "feature", values_to = "Count of distinct train") |>
  left_join(
    competition_df %>%
      summarize(across(all_of(features), n_distinct)) %>%
      pivot_longer(everything(), names_to = "feature", values_to = "Count of distinct test")
  ) %>% 
                   knitr::kable()
               
```

## Duplicated

Is this competition transaction already in the training data with a correct label?

```{r}
#| label: duplicates
#| warning: false
#| message: false

bind_rows(train_df %>% mutate(source = "train"),
              competition_df %>% mutate(label = NA_character_, source = "test")) |> 
    group_by_at(features) %>%
    mutate(num_dups = n(),
           dup_id = row_number()) %>% 
    ungroup() %>%
    group_by(source) %>%
    mutate(is_duplicated = dup_id > 1) %>% 
    count(is_duplicated) %>% 
                   knitr::kable()
               

```
                   



## Target

```{r}
#| label: outcome 
#| warning: false
#| message: false
#| fig.width: 6


train_df %>%
  summarize(outcome_sum = n(), .by = label) %>%
  arrange(outcome_sum) %>%
  mutate(prop = outcome_sum / nrow(train_df)) %>%
  mutate(ypos = cumsum(prop) - 0.5 * prop) %>%
  ggplot(aes(x = "", y = prop, fill = label)) +
  geom_bar(stat = "identity",
           width = 1,
           show.legend = FALSE) +
  geom_text(
    aes(
      y = ypos,
      label = paste0(label
                     , "\n", round(prop, 2) * 100, "%")
    ),
    color = "white",
    nudge_x = 0,
    size = 3
  ) +
  coord_polar("y", start = 0) +
  theme(
    axis.text = element_blank(),
    axis.title = element_blank()  ) +
  labs(title = "Higgs Boson", caption = "Data: Kaggle.com | Visual: Jim Gruman")

```
                              
           
                
# Machine Learning {.tabset .tabset-fade .tabset-pills}

## Recipe

```{r}
#| label: recipe

base_rec <- recipe(
    
    formula(paste0("label ~ ", 
               str_c(features,  collapse = " + "))),
    data = train_df
  ) %>% 

  step_zv(all_predictors()) 

                

folds <- vfold_cv(train_df, 
                  v = 3,
                  strata = label)                           
                                     
```



## Workflowset Ensemble

```{r}
#| label: workflowset
#| warning: false
#| message: false
#| fig.width: 12

boost_tree_lgbm_spec <- 
  boost_tree(
    trees = 100L,
   tree_depth = tune(),
   learn_rate =  tune(),
   min_n = tune(),
#   mtry = tune(),
#   loss_reduction = 9e-9
  ) %>% 
  set_engine(engine = "lightgbm",
             is_unbalance = TRUE,
             num_leaves = tune(),
             num_threads = cores
       #      boosting = "goss"   # this may slow the runtime
             ) %>%
  set_mode(mode = "classification") 

boost_tree_xgb_spec <- 
  boost_tree(
    trees = 100L,
    min_n = tune(),
    learn_rate = tune()
  ) %>% 
  set_engine(engine = "xgboost", nthread = cores) %>%
  set_mode(mode = "classification")                    


dep_models <- 
   workflow_set(
      preproc = list(base = base_rec,
                     base = base_rec),
      models = list(xgb = boost_tree_xgb_spec,
                    lgbm = boost_tree_lgbm_spec),
      cross = FALSE
   ) %>% 
  option_add_parameters() |> 
  option_add(
    control = control_stack_grid(),
    metrics = metric_set(mn_log_loss)
  )

xgb_params <- dep_models |> 
  extract_workflow("base_xgb") |> 
  parameters() |> 
  update(min_n = min_n(range = c(10,120)),
         learn_rate = learn_rate(range = c(-2,-1)))

lgbm_params <- dep_models |> 
  extract_workflow("base_lgbm") |> 
  parameters() |> 
  update(tree_depth = tree_depth(range = c(20,90)),
         num_leaves = num_leaves(),
         learn_rate = learn_rate(range = c(-2,-1)),
          min_n = min_n(range = c(40,120)))

dep_models <- dep_models |> 
  option_add(
    param_info = lgbm_params,
    id = "base_lgbm"
  ) |> 
  option_add(
    param_info = xgb_params,
    id = "base_xgb"
  ) |> 
   workflow_map("tune_grid", resamples = folds, grid = 9, 
                metrics = metric_set(roc_auc), verbose = TRUE)

autoplot(dep_models) +
  geom_text(aes(y = mean -0.01, label = wflow_id), angle = 90, hjust = 1)+
  theme(legend.position = "none")

rank_results(dep_models, rank_metric = "roc_auc", select_best = TRUE) %>% 
   select(rank, mean, model, wflow_id, .config)

dep_models %>%
  dplyr::filter(grepl("xgb", wflow_id)) %>%
  mutate(metrics = map(result, collect_metrics)) %>%
  dplyr::select(wflow_id, metrics) %>%
  tidyr::unnest(cols = metrics) |> 
  arrange(desc(mean))

dep_models |> 
  workflowsets::extract_workflow_set_result("base_xgb") |> 
  autoplot() +
  labs(title = "XGB Hyperparameter Search")

best_xgb_params <- dep_models |> 
  workflowsets::extract_workflow_set_result("base_xgb") |> 
  select_best(metric = "roc_auc")  
  
dep_models |> 
  workflowsets::extract_workflow("base_xgb") |> 
  finalize_workflow(best_xgb_params) |> 
  fit(train_df) |> 
  vip::vip(num_features = 30L)



dep_models %>%
  dplyr::filter(grepl("lgbm", wflow_id)) %>%
  mutate(metrics = map(result, collect_metrics)) %>%
  dplyr::select(wflow_id, metrics) %>%
  tidyr::unnest(cols = metrics) |> 
  arrange(desc(mean))

dep_models |> 
  workflowsets::extract_workflow_set_result("base_lgbm") |> 
  autoplot() +
  labs(title = "LGBM Hyperparameter Search")

best_lgbm_params <- dep_models |> 
  workflowsets::extract_workflow_set_result("base_lgbm") |> 
  select_best(metric = "roc_auc")  
  
dep_models |> 
  workflowsets::extract_workflow("base_lgbm") |> 
  finalize_workflow(best_lgbm_params) |> 
  fit(train_df) |> 
  vip::vip(num_features = 30L)


dep_stack <- stacks() %>%
  add_candidates(dep_models) %>%
  blend_predictions(  metric = metric_set(roc_auc),
      penalty = c(10^seq(-1.7, -0.3, 0.1)),
      non_negative = TRUE,
      control = tune::control_grid(allow_par = TRUE))

autoplot(dep_stack)

autoplot(dep_stack, type = "members")                   

classification_fit <- dep_stack %>% 
    fit_members()

```

# Performance {.tabset .tabset-fade .tabset-pills}

## Submission
```{r }                   
#| label: submission
#| warning: false
#| message: false
                   
augment(classification_fit, train_df) %>% 
  conf_mat(label, .pred_class) %>%
  yardstick:::autoplot.conf_mat(type = "heatmap")

submit_df <-  augment(classification_fit , competition_df, type= "prob") %>%
       mutate(id = row_number()) |> 
       select(id, label = .pred_1)

head(submit_df)  %>% 
     knitr::kable()      

submit_df  %>% 
  write_csv("submission.csv")
```  