---
title: "Personality Binary Classifcation"
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: cosmo
    highlight: tango
    code_folding: hide
---
  
# Introduction  {.tabset .tabset-fade .tabset-pills}

The goal of this competition is to predict a personality trait.

My notebook serves as a demonstration of some of the possible techniques available to arrive at a solution.  I intend to add to this as I have time available. Your questions and comments are welcome.

Lets dive right in.

The Kaggle kernels have many of the common r packages built in.  

![https://unsplash.com/@amseaman](https://images.unsplash.com/photo-1521220546621-cf34a1165c67?q=80&w=1176&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D)

## Load libraries

```{r }
#| label: setup
#| warning: false
#| message: false

if (dir.exists("/kaggle")){
  path <- "/kaggle/input/playground-series-s5e7/"
  orig_path <- "/kaggle/input/extrovert-vs-introvert-behavior-data-backup/"

#options(repos = c(CRAN = "https://packagemanager.posit.co/cran/2025-06-30"))
install.packages("pak")
pak::pak("bonsai")

remotes::install_url('https://github.com/catboost/catboost/releases/download/v1.2.8/catboost-R-linux-x86_64-1.2.8.tgz', 
                     INSTALL_opts = c("--no-multiarch", "--no-test-load"),
                    quiet = TRUE)  

# future::plan("multisession", workers = future::availableCores())    

} else {
  path <- stringr::str_c(here::here("data"),"/")
  orig_path <- stringr::str_c(here::here("data"),"/")

  future::plan("multisession", workers = future::availableCores(omit = 2))
  
}
 
suppressPackageStartupMessages({
library(tidyverse, quietly = TRUE) # metapackage of all tidyverse packages
library(tidymodels) # metapackage see https://www.tidymodels.org/

library(correlationfunnel)    
  
library(bonsai)  # interface to lighgbm and catboost
library(catboost)

library(stacks)  # ensembling
    
library(DALEXtra) # Tidymodels Explainability     

})

tidymodels_prefer()
conflicted::conflicts_prefer(brulee::coef)

options(tidymodels.dark = TRUE)

theme_set(ggdark::dark_theme_minimal())

```

## Load Data


```{r }
#| label: load data
#| warning: false
#| message: false

preprocessor <- function(dataframe) {

dataframe <- dataframe %>%
    janitor::clean_names() |>

    mutate(across(c(where(is.character)), \(x) as.factor(x))) |> 
    mutate(across(c(stage_fear, drained_after_socializing), \(x) as.numeric(x) - 1)) |>

    mutate(
 #     across(-id, \(x) replace_na(x, -1)),
      time_spent_alone_f = factor(str_c("tsa", time_spent_alone)),
      stage_fear_f = factor(str_c("sf", stage_fear)),
      social_event_attendance_f  = factor(str_c("sea", social_event_attendance )),
      going_outside_f  = factor(str_c("go", going_outside )),
      drained_after_socializing_f  = factor(str_c("das", drained_after_socializing )),
      friends_circle_size_f  = factor(str_c("fcs", friends_circle_size )),
      post_frequency_f  = factor(str_c("pf", post_frequency))
    ) |> 
   mutate(across(ends_with("_f"), \(x) fct_explicit_na(x, "None")))    

return(dataframe)
}

raw_df <- read_csv(str_c(path, "train.csv"),
                   show_col_types = FALSE) |> 

          bind_rows(
                     read_csv(str_c(orig_path,"personality_dataset.csv")) 
          ) |>

          preprocessor() 

tst_df <- read_csv(str_c(path, "test.csv"),
                   show_col_types = FALSE)  |>  
  preprocessor() 

# because we already know the test set, let's remove the train set factor levels that do not correspond with anything on the test set
for (col in names(raw_df)) {
    if (is.factor(raw_df[[col]]) & col != "personality") {
      # Get levels in train and test dataframes
      raw_levels <- levels(raw_df[[col]])
      tst_levels <- levels(tst_df[[col]])
      
      # Identify levels in train not in test
      new_levels <- setdiff(raw_levels, tst_levels)
      
      # Set these levels to NA in train dataframe
      raw_df[[col]] <- factor(raw_df[[col]], levels = c(tst_levels, new_levels))
      raw_df[[col]][raw_df[[col]] %in% new_levels] <- NA_character_
    }
  }

# the synthetic playground competitions seem to perform better when numerics are also included as factors
all_df <-
    bind_rows(raw_df %>% mutate(source = "train"),
              tst_df %>% mutate(source = "test")) 

cluster_fit <- all_df |> 
  select(where(is.numeric), -id) |> 
  mutate(across(everything(), \(x) replace_na(x, -1))) |> 
  mutate(across(where(is.numeric), scale)) |> 
  kmeans(centers = 25)

all_df <- all_df |> 
  bind_cols(tibble(cluster = factor(fitted(cluster_fit, method = "classes"))))

train_df <- all_df %>% 
  filter(source == "train") %>% 
  select(-source) 

competition_df <- all_df %>% 
  filter(source == "test") %>% 
  select(-source, -personality)


```


# EDA {.tabset .tabset-fade .tabset-pills}

## Features

```{r}
#| label: Features
#| warning: false
#| message: false
#| fig.width: 6


features <- train_df %>%
  select(-id, -personality) |> 
  names()

train_df <- train_df %>% 
  distinct(pick(all_of(features)), .keep_all = TRUE)

nom_features <- train_df %>%
  select(all_of(features)) %>%
  select(where(is.character), where(is.factor)) %>%
  names() 

logical_features <- train_df %>%
  select(all_of(features)) %>%
  select(where(is.logical)) %>%
  names() 

num_features <- train_df %>%
  select(all_of(features)) %>%
  select(where(is.numeric)) %>%
  names()
```

Nominal features:

`r nom_features`

Numeric features: 

`r num_features`

Logical features: 

`r logical_features`


Size of the combined train and competition datasets:

`r nrow(all_df)`

Size of the split made available to machine learning

`r nrow(train_df)`



## Numeric features

```{r}
#| label: numeric
#| warning: false
#| message: false
#| fig.height: 6
#| fig.width: 10

train_df %>% 
  select(all_of(num_features), personality) %>% 
  pivot_longer(-personality,
    names_to = "metric",
    values_to = "value"
  ) %>%
  ggplot(aes(value)) +
  stat_density(aes(color = personality), geom = "line", position = "identity") +
  scale_color_brewer(type = "qual", palette = "Dark2") +
  facet_wrap(vars(metric), scales = "free", ncol = 3) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.title.position = "plot") +
  labs(color = "Fertilizer", 
       title = "Numeric Feature Univariate Distributions",
       caption = "Data: Kaggle.com | Visual: Jim Gruman")


```

## Nominal features

Explore the distribution of outcome class by factor level.


```{r}
#| label: nominal
#| warning: false
#| message: false
#| fig.height: 24
#| fig.width: 12



train_df %>% 
  select(all_of(nom_features), personality) %>% 
  mutate(across(nom_features, fct_lump_n,n = 10, other_level = 'other')) %>%

  pivot_longer(-personality,
    names_to = "metric",
    values_to = "value"
  ) %>%
    
  summarise(n = n(),
            .by = c(personality, metric, value)) %>%

  mutate(value = tidytext::reorder_within(value, n, metric)) %>%
    
  ggplot(aes(x = n, y = value, fill = personality)) +
  geom_col(position = "fill") +

  tidytext::scale_y_reordered() +
  scale_x_continuous(n.breaks = 3, guide = guide_axis(n.dodge = 2))  +
  facet_wrap(vars(metric), scales = "free", ncol = 2) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
       legend.position = "bottom") +
  labs(title = "Proportion of Outcome in Nominal Feature Counts",
       fill = NULL,
       caption = "Data: Kaggle | Visual: Jim Gruman")

```


## Counts of Missingness

The test set is missing one wind direction. We will fill it in with the median of all of the data.
                  
```{r}
#| label: counts of missingness

train_df %>% 
  summarize(across(all_of(features), function(x) sum(is.na(x)))) %>% 
  pivot_longer(everything(),
              names_to = "feature",
              values_to = "Count of Missing") %>% 
                   knitr::kable()

competition_df %>% 
  summarize(across(all_of(features), function(x) sum(is.na(x)))) %>% 
  pivot_longer(everything(),
              names_to = "feature",
              values_to = "Count of Missing") %>% 
                   knitr::kable()

```

## Counts of Distinct
                   
               
```{r}
#| label: counts of distinct
               
train_df %>%
  summarize(across(all_of(features), n_distinct)) %>%
  pivot_longer(everything(), names_to = "feature", values_to = "Count of distinct train") |>
  left_join(
    competition_df %>%
      summarize(across(all_of(features), n_distinct)) %>%
      pivot_longer(everything(), names_to = "feature", values_to = "Count of distinct test"),
    by = join_by(feature)
  ) %>% 
                   knitr::kable()
               
```

## Duplicated

Is this competition transaction already in the training data with a correct personality?

```{r}
#| label: duplicates
#| warning: false
#| message: false

bind_rows(train_df %>% mutate(source = "train"),
              competition_df %>% mutate(personality= NA_character_, source = "test")) |> 
    group_by_at(features) %>%
    mutate(num_dups = n(),
           dup_id = row_number()) %>% 
    ungroup() %>%
    group_by(source) %>%
    mutate(is_duplicated = dup_id > 1) %>% 
    count(is_duplicated) %>% 
                   knitr::kable()
               

```

## Pairwise Correlations
                   
`ggcorrplot` provides a quick look at numeric features where the correlation may be significant. 

```{r}
#| label: pairwise correlations
#| fig.width: 6
#| fig.height: 6                   
                   
train_df %>% 
  select(all_of(num_features), personality) %>%
  mutate(across(everything(), \(x) replace_na(x, -1))) |> 
  mutate(personality = as.numeric(personality) -1) |> 
  cor() %>% 
  ggcorrplot::ggcorrplot(hc.order = TRUE, lab = TRUE,
    type = "lower", insig = "blank") +
  labs(title = "Pairwise Correlations Training Set")
                   
competition_df %>% 
  select(all_of(num_features)) %>% 
  mutate(across(everything(), \(x) replace_na(x, -1))) |> 
  cor() %>% 
  ggcorrplot::ggcorrplot(hc.order = TRUE, lab = TRUE,
    type = "lower", insig = "blank") +
  labs(title = "Pairwise Correlations Competition Set")

``` 

## Correlation Funnel


```{r}
#| label: correlation funnel 
#| warning: false
#| message: false
#| fig.width: 6
#| fig.height: 6

personality_df <- train_df |>
  select(all_of(num_features), personality) %>%
  na.omit() 

train_df %>%
  select(all_of(num_features)) %>%
  na.omit() |>
  correlationfunnel::binarize(one_hot = TRUE, n_bins = 9) %>%
  bind_cols(personality_df) |>
  mutate(personality = as.numeric(personality) - 1) |> 
  correlate(target = personality) %>%
  plot_correlation_funnel()

```                   
               

## Target

```{r}
#| label: outcome 
#| warning: false
#| message: false
#| fig.width: 6


train_df %>%
  summarize(outcome_sum = n(), .by = personality) %>%
  arrange(outcome_sum) %>%
  mutate(prop = outcome_sum / nrow(train_df)) %>%
  mutate(ypos = cumsum(prop) - 0.5 * prop) %>%
  ggplot(aes(x = "", y = prop, fill = personality)) +
  geom_bar(stat = "identity",
           width = 1,
           show.legend = FALSE) +
  geom_text(
    aes(
      y = ypos,
      label= paste0(personality
                     , "\n", round(prop, 2) * 100, "%")
    ),
    color = "white",
    nudge_x = 0,
    size = 3
  ) +
  coord_polar("y", start = 0) +
  theme(
    axis.text = element_blank(),
    axis.title = element_blank()  ) +
  labs(title = "Personality", caption = "Data: Kaggle.com | Visual: Jim Gruman")

```                            
           
                
# Machine Learning {.tabset .tabset-fade .tabset-pills}

## Recipe

```{r}
#| label: recipe
                   
base_rec <- recipe(
    
    formula(paste0("personality ~ ", 
               str_c(features,  collapse = " + "))),
    data = train_df
  ) 
                   
impute_rec <- base_rec |> 
  step_impute_median(all_numeric_predictors())

dummy_rec <- impute_rec|> 
  step_dummy(all_nominal_predictors()) |> 
  step_normalize(all_predictors())                         
                 

folds <- vfold_cv(train_df, v = 10, strata = personality)

                                     
```



## Workflowset Ensemble

```{r}
#| label: workflowset
#| warning: false
#| message: false
#| fig.width: 6

boost_tree_lgbm_spec <- 
  boost_tree(
    trees = 50L,
   tree_depth = tune(),
   learn_rate =  tune(),
   min_n = tune()
  ) %>% 
  set_engine(engine = "lightgbm",
             is_unbalance = TRUE,
             num_leaves = tune()
             ) %>%
  set_mode(mode = "classification") 

boost_tree_catboost_spec <- 
  boost_tree(
    trees = 50L,
     learn_rate =  tune()
  ) %>% 
  set_engine(engine = "catboost" ) %>%
  set_mode(mode = "classification") 

logistic_reg_glmnet_spec <-
  logistic_reg(penalty = tune(), mixture = tune()) %>%
  set_engine('glmnet')           

dep_models <- 
   workflow_set(
      preproc = list(base = base_rec,
#                     impute = impute_rec,
                     dummy = dummy_rec),
      models = list(lgbm = boost_tree_lgbm_spec,
#                    catboost = boost_tree_catboost_spec,
                    glmnet = logistic_reg_glmnet_spec),
      cross = FALSE
   ) %>% 
  option_add_parameters() |> 
  option_add(
    control = finetune::control_sim_anneal(save_pred = TRUE,save_workflow = TRUE),
    metrics = metric_set(accuracy)
  )

lgbm_params <- dep_models |> 
  extract_workflow("base_lgbm") |> 
  parameters() |> 
  update(
      min_n = min_n(range = c(3,70)),
      tree_depth = tree_depth(range = c(20,100)),
      learn_rate = learn_rate(range = c(-2.4,-0.6)),
      num_leaves = num_leaves(range = c(10,400))       
         )
             

#catboost_params <- dep_models |> 
#  extract_workflow("impute_catboost") |> 
#  parameters() |>
#  update(
#          learn_rate = learn_rate(range = c(-4.5,-3.0))
#  ) 
                   
dep_models <- dep_models |> 
  option_add(
    param_info = lgbm_params,
    id = "base_lgbm"
  ) |> 
#  option_add(
#    param_info = catboost_params,
#    id = "impute_catboost"
#  ) |> 
   workflow_map("tune_sim_anneal", resamples = folds, iter = 3, 
                metrics = metric_set(mn_log_loss, accuracy), verbose = TRUE)

rank_results(dep_models, rank_metric = "accuracy", select_best = TRUE)                    

autoplot(dep_models) +
  geom_text(aes(y = mean, label= wflow_id), angle = 90, vjust = 0, nudge_x = 0.4)+
  theme(legend.position = "none")

```

## Hyperparameters and Feature Importance

```{r }                   
#| label: parameters
#| warning: false
#| message: false    
#| fig.height: 6               

dep_models %>%
  dplyr::filter(grepl("base_lgbm", wflow_id)) %>%
  dplyr::mutate(metrics = purrr::map(result, tune::collect_metrics)) %>%
  dplyr::select(wflow_id, metrics) %>%
  tidyr::unnest(cols = metrics) |> 
  arrange(desc(mean))

dep_models |> 
  workflowsets::extract_workflow_set_result("base_lgbm") |> 
  autoplot() +
  labs(title = "LGBM Hyperparameter Search")

best_params <- dep_models |> 
  workflowsets::extract_workflow_set_result("base_lgbm") |> 
  select_best(metric = "accuracy")  
                   
#dep_models %>%
#  dplyr::filter(grepl("impute_catboost", wflow_id)) %>%
#  dplyr::mutate(metrics = purrr::map(result, tune::collect_metrics)) %>%
#  dplyr::select(wflow_id, metrics) %>%
#  tidyr::unnest(cols = metrics) |> 
#  arrange(desc(mean))

#dep_models |> 
#  workflowsets::extract_workflow_set_result("impute_catboost") |> 
#  autoplot() +
#  labs(title = "Catboost Hyperparameter Search")

#best_params <- dep_models |> 
#  workflowsets::extract_workflow_set_result("impute_catboost") |> 
#  select_best(metric = "accuracy")  


ens <- stacks::stacks() %>%
  stacks::add_candidates(dep_models) %>%
  stacks::blend_predictions(  metric = metric_set(accuracy),
      penalty = c(10^seq(-2.7, -0.4, 0.1)),
      non_negative = TRUE,
      control = tune::control_grid(allow_par = TRUE))

autoplot(ens)

autoplot(ens, "weights")

classification_fit <- fit_members(ens)                   
                                
```


```{r}
#| label: explainer
#| warning: false
#| message: false


explainer <- 
  explain_tidymodels(
    classification_fit, 
    data = train_df %>% dplyr::select(all_of(features)), 
    y = as.numeric(train_df$personality),
    label = "Ensemble",
    verbose = FALSE
  )  %>% 
  model_parts()

ggplot_imp <- function(...) {
  obj <- list(...)
  metric_name <- attr(obj[[1]], "loss_name")
  metric_lab <- paste(metric_name, 
                      "after permutations\n(higher indicates more important)")
  
  full_vip <- bind_rows(obj) %>%
    filter(variable != "_baseline_")
  
  perm_vals <- full_vip %>% 
    filter(variable == "_full_model_") %>% 
    group_by(label) %>% 
    summarise(dropout_loss = mean(dropout_loss))
  
  p <- full_vip %>%
    filter(variable != "_full_model_") %>% 
    mutate(variable = fct_reorder(variable, -dropout_loss)) %>%
    ggplot(aes(dropout_loss, variable)) 
  
  if(length(obj) > 1) {
    p <- p + 
      facet_wrap(vars(label)) +
      geom_vline(data = perm_vals, aes(xintercept = dropout_loss, color = label),
                 linewidth = 1.4, lty = 2, alpha = 0.7) +
      geom_boxplot(aes(color = label, fill = label), alpha = 0.2)
  } else {
    p <- p + 
      geom_vline(data = perm_vals, aes(xintercept = dropout_loss),
                 linewidth = 1.4, lty = 2, alpha = 0.7) +
      geom_boxplot(fill = "#91CBD765", alpha = 0.4)
    
  }
  p +
    theme(legend.position = "none") +
    labs(x = metric_lab, 
         y = NULL,  fill = NULL,  color = NULL)
}
                   
ggplot_imp(explainer)      
                   

``` 


## Submission


```{r }                   
#| label: submission
#| warning: false
#| message: false


augment(classification_fit, train_df) %>% 
  conf_mat(personality, .pred_class) %>%
  yardstick:::autoplot.conf_mat(type = "heatmap") +
  scale_fill_distiller(palette = "RdPu")

submit_df <-  augment(
  classification_fit,
  competition_df %>%
    left_join(train_df %>% select(-id), by = all_of(features)) %>%
    rename(train_personality = personality)
) %>%
  transmute(id, personality = if_else(is.na(train_personality), .pred_class, train_personality))

head(submit_df)  %>% 
     knitr::kable()      

submit_df  %>% 
  write_csv("submission.csv")
```  